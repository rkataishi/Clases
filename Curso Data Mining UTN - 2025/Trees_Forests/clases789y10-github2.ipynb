{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports_unificados_completos.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import subprocess\n",
    "import holidays\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import (\n",
    "    DecisionTreeClassifier, DecisionTreeRegressor,\n",
    "    export_text, export_graphviz, plot_tree, _tree\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Funciones personalizadas\n",
    "from mis_funciones.view_dectree import view_dectree\n",
    "from mis_funciones.view_dectree_v import view_dectree_v\n",
    "from mis_funciones.view_detail_text_tree import (\n",
    "    view_text_tree_detailed, view_text_tree_pruned,\n",
    "    extract_sorted_tree_paths\n",
    ")\n",
    "from mis_funciones.view_detail_text_cattree import (\n",
    "    view_text_cattree_detailed, view_text_cattree_pruned\n",
    ")\n",
    "from mis_funciones.describe_vars import describe_vars\n",
    "from mis_funciones.describe_vars_txt import describe_vars_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('dataset_suscripciones.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_vars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='nivel', y='precio')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.boxplot(data=df, x='nivel', y='precio')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=df, x='nivel', y='descuento_pct')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=df, x='nivel', y='rating_promedio')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=df, x='nivel', y='ventas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='ventas', hue='curso', multiple='stack', bins=range(0,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='edad', hue='ventas', multiple='stack', bins=100)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular los porcentajes relativos\n",
    "df_pct = df.groupby(['ventas', 'dispositivo']).size().unstack()\n",
    "df_pct = df_pct.div(df_pct.sum(axis=1), axis=0) * 100\n",
    "\n",
    "ax = df_pct.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Cantidad de ventas por sesión')\n",
    "plt.ylabel('Porcentaje')\n",
    "plt.title('Distribución porcentual de dispositivos por cantidad de ventas')\n",
    "plt.legend(title='Dispositivo')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='ventas', hue='referrer', multiple='stack', bins=range(0,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular los porcentajes relativos\n",
    "df_pct = df.groupby(['ventas', 'referrer']).size().unstack()\n",
    "df_pct = df_pct.div(df_pct.sum(axis=1), axis=0) * 100\n",
    "\n",
    "ax = df_pct.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Cantidad de ventas por sesión')\n",
    "plt.ylabel('Porcentaje')\n",
    "plt.title('Distribución porcentual de referrer por cantidad de ventas')\n",
    "plt.legend(title='Referrer')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "tabla = pd.crosstab(df['referrer'], df['ventas'])\n",
    "tabla_pct = tabla.div(tabla.sum(axis=0), axis=1)\n",
    "sns.heatmap(tabla_pct, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=False)\n",
    "plt.xlabel('Cantidad de ventas por sesión')\n",
    "plt.ylabel('Canal de origen (referrer)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='ventas', hue='es_domingo', multiple='stack', bins=range(0,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='ventas', hue='es_feriado', multiple='stack', bins=range(0,10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "df_diario = df.groupby('fecha').agg({\n",
    "    'ventas': 'mean',\n",
    "    'clicks': 'mean',\n",
    "    'tiempo_browsing': 'mean',\n",
    "    'paginas_visitadas': 'mean',\n",
    "    'edad': 'mean',\n",
    "    'logueado': 'mean',\n",
    "    'codigo_promocional': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='ventas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='clicks')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='tiempo_browsing')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='paginas_visitadas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='edad')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='logueado')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(data=df_diario, x='fecha', y='codigo_promocional')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "df_diario = df.groupby('fecha').agg({\n",
    "    'ventas': 'mean',                    # promedio de ventas por sesión en el día\n",
    "    'clicks': 'sum',                     # total de clics del día\n",
    "    'tiempo_browsing': 'sum',            # total de tiempo de navegación del día\n",
    "    'paginas_visitadas': 'sum',          # total de páginas vistas del día\n",
    "    'edad': 'mean',                      # edad promedio de los usuarios del día\n",
    "    'logueado': 'sum',                   # total de sesiones logueadas del día\n",
    "    'codigo_promocional': 'sum'          # total de usuarios que usaron código ese día\n",
    "}).reset_index()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_diario, x='clicks', y='ventas')\n",
    "plt.xlabel('Total de clics diarios')\n",
    "plt.ylabel('Promedio de ventas por sesión')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_diario, x='tiempo_browsing', y='ventas')\n",
    "plt.xlabel('Total de tiempo de navegación (segundos) por día')\n",
    "plt.ylabel('Promedio de ventas por sesión')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_diario, x='paginas_visitadas', y='ventas')\n",
    "plt.xlabel('Total de páginas vistas por día')\n",
    "plt.ylabel('Promedio de ventas por sesión')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_diario, x='edad', y='ventas')\n",
    "plt.xlabel('Edad promedio de usuarios por día')\n",
    "plt.ylabel('Promedio de ventas por sesión')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_diario, x='logueado', y='ventas')\n",
    "plt.xlabel('Cantidad de sesiones logueadas por día')\n",
    "plt.ylabel('Promedio de ventas por sesión')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df_diario, x='codigo_promocional', y='ventas')\n",
    "plt.xlabel('Cantidad de usuarios con código promocional por día')\n",
    "plt.ylabel('Promedio de ventas por sesión')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_vars(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de relaciones\n",
    "## Regresiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- REGRESIÓN BASE ---\n",
    "df_reg_base = pd.DataFrame({\n",
    "    'Ventas': df['ventas'].astype(float),\n",
    "    'Clicks': df['clicks'].astype(float),\n",
    "    'Tiempo_Browsing': df['tiempo_browsing'].astype(float),\n",
    "    'Paginas_Visitadas': df['paginas_visitadas'].astype(float),\n",
    "    'Logueado': df['logueado'].astype(int),\n",
    "    'Codigo_Promocional': df['codigo_promocional'].astype(int),\n",
    "    'Es_Feriado': df['es_feriado'].astype(int),\n",
    "    'Es_Domingo': df['es_domingo'].astype(int),\n",
    "    'Dia_Semana': df['dia_semana'].astype(int),\n",
    "    'Hora': df['hora'].astype(int),\n",
    "    'Dias_Desde_Promocion': df['dias_desde_promocion'].astype(int)\n",
    "})\n",
    "X_base = sm.add_constant(df_reg_base.drop(columns=['Ventas']))\n",
    "modelo_base = sm.OLS(df_reg_base['Ventas'], X_base).fit()\n",
    "\n",
    "print(\"\\n=== REGRESIÓN BASE ===\\n\")\n",
    "print(modelo_base.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- REGRESIÓN EXTENDIDA ---\n",
    "df_reg_ext = pd.DataFrame({\n",
    "    'Ventas': df['ventas'].astype(float),\n",
    "    'Clicks': df['clicks'].astype(float),\n",
    "    'Tiempo_Browsing': df['tiempo_browsing'].astype(float),\n",
    "    'Paginas_Visitadas': df['paginas_visitadas'].astype(float),\n",
    "    'Precio': df['precio'].astype(float),\n",
    "    'Descuento': df['descuento_pct'].astype(float),\n",
    "    'Rating': df['rating_promedio'].astype(float),\n",
    "    'Edad': df['edad'].astype(float),\n",
    "    'Es_Feriado': df['es_feriado'].astype(int),\n",
    "    'Es_Domingo': df['es_domingo'].astype(int),\n",
    "    'Dia_Semana': df['dia_semana'].astype(int),\n",
    "    'Hora': df['hora'].astype(int),\n",
    "    'Dias_Desde_Promocion': df['dias_desde_promocion'].astype(int),\n",
    "    'Logueado': df['logueado'].astype(int),\n",
    "    'Codigo_Promocional': df['codigo_promocional'].astype(int)\n",
    "})\n",
    "cat_vars = ['curso', 'nivel', 'dispositivo', 'referrer', 'nivel_educativo']\n",
    "df_dummies = pd.get_dummies(df[cat_vars], drop_first=True).astype(float)\n",
    "df_reg_ext = pd.concat([df_reg_ext, df_dummies], axis=1)\n",
    "X_ext = sm.add_constant(df_reg_ext.drop(columns=['Ventas']))\n",
    "modelo_ext = sm.OLS(df_reg_ext['Ventas'], X_ext).fit()\n",
    "\n",
    "print(\"\\n=== REGRESIÓN EXTENDIDA ===\\n\")\n",
    "print(modelo_ext.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- COMPARACIÓN ---\n",
    "def marcar(valor, p):\n",
    "    if p < 0.01:\n",
    "        return f\"{valor:.4f}***\"\n",
    "    elif p < 0.05:\n",
    "        return f\"{valor:.4f}** \"\n",
    "    elif p < 0.1:\n",
    "        return f\"{valor:.4f}*  \"\n",
    "    else:\n",
    "        return f\"{valor:.4f}   \"\n",
    "\n",
    "param_base = pd.Series({k: marcar(v, modelo_base.pvalues[k]) for k, v in modelo_base.params.items()}, name=\"Regresión Base\")\n",
    "param_ext = pd.Series({k: marcar(v, modelo_ext.pvalues[k]) for k, v in modelo_ext.params.items()}, name=\"Regresión Extendida\")\n",
    "comparacion = pd.concat([param_base, param_ext], axis=1)\n",
    "\n",
    "# Agregar R² al final de la tabla\n",
    "r2_row = pd.DataFrame({\n",
    "    'Regresión Base': [f\"R² = {modelo_base.rsquared:.4f}\"],\n",
    "    'Regresión Extendida': [f\"R² = {modelo_ext.rsquared:.4f}\"]\n",
    "}, index=[\" \"])\n",
    "\n",
    "comparacion = pd.concat([comparacion, r2_row])\n",
    "\n",
    "print(\"\\n=== COMPARACIÓN DE REGRESORES Y SIGNIFICACIÓN ===\\n\")\n",
    "print(comparacion.fillna(\"\").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hay una relación lineal entre paginas visitadas y ventas, esto se captura bien en las regresiones\n",
    "\n",
    "mean_std = df.groupby('paginas_visitadas', observed=True)['ventas'].agg(['mean', 'std', 'count']).reset_index()\n",
    "mean_std['se'] = mean_std['std'] / mean_std['count']**0.5  # error estándar\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=mean_std, x='paginas_visitadas', y='mean', color='steelblue', errorbar=None, alpha=0.6, linewidth=1, edgecolor='darkblue')\n",
    "plt.errorbar(x=mean_std['paginas_visitadas'], y=mean_std['mean'], yerr=mean_std['se'],\n",
    "            fmt='none', ecolor='lightgray', capsize=3, linewidth=1)\n",
    "z_curva = np.polyfit(mean_std['paginas_visitadas'], mean_std['mean'], 3)\n",
    "p_curva = np.poly1d(z_curva)\n",
    "plt.plot(mean_std['paginas_visitadas'], p_curva(mean_std['paginas_visitadas']), color='red', linestyle='--', linewidth=1.5)\n",
    "z_lineal = np.polyfit(mean_std['paginas_visitadas'], mean_std['mean'], 1)\n",
    "p_lineal = np.poly1d(z_lineal)\n",
    "plt.plot(mean_std['paginas_visitadas'], p_lineal(mean_std['paginas_visitadas']), color='gray', linestyle='-', linewidth=1.2)\n",
    "plt.fill_between(mean_std['paginas_visitadas'], p_lineal(mean_std['paginas_visitadas']) - mean_std['se'], \n",
    "                p_lineal(mean_std['paginas_visitadas']) + mean_std['se'], color='gray', alpha=0.5)\n",
    "plt.title(\"Promedio de Ventas por Páginas Visitadas\")\n",
    "plt.xlabel(\"Páginas Visitadas\")\n",
    "plt.ylabel(\"Promedio de Ventas\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hay una relación clara entre precio y ventas, por lo que la aproximación lineal es insuficiente. Vamos a necesitar otro modelo.\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(df)))\n",
    "scatter = plt.scatter(df['precio'], df['ventas'], \n",
    "                    c=df['precio'],\n",
    "                    cmap='inferno_r', # Alternatives: plasma, magma, inferno, cividis\n",
    "                    alpha=0.5)\n",
    "plt.colorbar(scatter, label='Precio')\n",
    "plt.title(\"Relación no lineal: Precio vs Ventas\")\n",
    "plt.xlabel(\"Precio\")\n",
    "plt.ylabel(\"Ventas\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En efecto... PRECIO no da ningun efecto...y claramente su relación con ventas es no lineal. \n",
    "# Precio -->   beta:  -0.0002    p-value:   0.950 \n",
    "\n",
    "# veamos nuevamente la regresión extendida...\n",
    "df_reg_ext = pd.DataFrame({\n",
    "    'Ventas': df['ventas'].astype(float),\n",
    "    'Clicks': df['clicks'].astype(float),\n",
    "    'Tiempo_Browsing': df['tiempo_browsing'].astype(float),\n",
    "    'Paginas_Visitadas': df['paginas_visitadas'].astype(float),\n",
    "    'Precio': df['precio'].astype(float),\n",
    "    'Descuento': df['descuento_pct'].astype(float),\n",
    "    'Rating': df['rating_promedio'].astype(float),\n",
    "    'Edad': df['edad'].astype(float),\n",
    "    'Es_Feriado': df['es_feriado'].astype(int),\n",
    "    'Es_Domingo': df['es_domingo'].astype(int),\n",
    "    'Dia_Semana': df['dia_semana'].astype(int),\n",
    "    'Hora': df['hora'].astype(int),\n",
    "    'Dias_Desde_Promocion': df['dias_desde_promocion'].astype(int),\n",
    "    'Logueado': df['logueado'].astype(int),\n",
    "    'Codigo_Promocional': df['codigo_promocional'].astype(int)\n",
    "})\n",
    "cat_vars = ['curso', 'nivel', 'dispositivo', 'referrer', 'nivel_educativo']\n",
    "df_dummies = pd.get_dummies(df[cat_vars], drop_first=True).astype(float)\n",
    "df_reg_ext = pd.concat([df_reg_ext, df_dummies], axis=1)\n",
    "X_ext = sm.add_constant(df_reg_ext.drop(columns=['Ventas']))\n",
    "modelo_ext = sm.OLS(df_reg_ext['Ventas'], X_ext).fit()\n",
    "\n",
    "print(\"\\n=== REGRESIÓN EXTENDIDA ===\\n\")\n",
    "print(modelo_ext.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Decision trees, round 2\n",
    "\n",
    "\n",
    "# \n",
    "![](./model_outputs/output.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es un Árbol de Regresión?\n",
    "- Es un algoritmo que predice valores numéricos (continuos) mediante divisiones sucesivas del espacio de datos.\n",
    "- A cada división se le llama split y ocurre sobre una variable que minimiza el error de predicción (MSE).\n",
    "- El resultado es una estructura de árbol con reglas condicionales.\n",
    "\n",
    "---\n",
    "\n",
    "### Ejemplo mínimo\n",
    "\n",
    "##### Evaluación de todos los cortes posibles en `precio` para explicar `ventas`\n",
    "\n",
    "Usamos el siguiente dataset:\n",
    "\n",
    "| precio | ventas |\n",
    "|--------|--------|\n",
    "| 10     | 6      |\n",
    "| 15     | 5      |\n",
    "| 20     | 3      |\n",
    "| 25     | 2      |\n",
    "| 30     | 1      |\n",
    "\n",
    "Posibles cortes entre valores únicos ordenados:\n",
    "\n",
    "| Cortes candidatos | Valor |\n",
    "|------------------|-------|\n",
    "| (10+15)/2        | 12.5  |\n",
    "| (15+20)/2        | 17.5  |\n",
    "| (20+25)/2        | 22.5  |\n",
    "| (25+30)/2        | 27.5  |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Calculamos el MSE para corte o grupo, a ver cuál es mejor (menos error MSE, mejor): \n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{n}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##### Corte 1: precio ≤ 12.5\n",
    "\n",
    "- Grupo 1: [10] → media = 6  \n",
    "- Grupo 2: [15, 20, 25, 30] → media = 2.75  \n",
    "\n",
    "MSE = $\\frac{(6-6)^2 + (5-2.75)^2 + (3-2.75)^2 + (2-2.75)^2 + (1-2.75)^2}{5}$  \n",
    "MSE = $\\frac{0 + 5.06 + 0.06 + 0.56 + 3.06}{5} = \\mathbf{1.75}$\n",
    "\n",
    "| precio | ventas | grupo 1 (μ=6) | grupo 2 (μ=2.75) | MSE Corte 1 |\n",
    "|--------|--------|----------------|------------------|--------------|\n",
    "| 10     | 6      | x              |                  | 1.75         |\n",
    "| 15     | 5      |                | x                |              |\n",
    "| 20     | 3      |                | x                |              |\n",
    "| 25     | 2      |                | x                |              |\n",
    "| 30     | 1      |                | x                |              |\n",
    "\n",
    "---\n",
    "\n",
    "##### Corte 2: precio ≤ 17.5\n",
    "\n",
    "- Grupo 1: [10, 15] → media = 5.5  \n",
    "- Grupo 2: [20, 25, 30] → media = 2.0  \n",
    "\n",
    "MSE = $\\frac{(6-5.5)^2 + (5-5.5)^2 + (3-2)^2 + (2-2)^2 + (1-2)^2}{5}$  \n",
    "MSE = $\\frac{0.25 + 0.25 + 1 + 0 + 1}{5} = \\mathbf{0.5}$\n",
    "\n",
    "| precio | ventas | grupo 1 (μ=5.5) | grupo 2 (μ=2.0) | MSE Corte 2 |\n",
    "|--------|--------|------------------|-----------------|-------------|\n",
    "| 10     | 6      | x                |                 | 0.5         |\n",
    "| 15     | 5      | x                |                 |             |\n",
    "| 20     | 3      |                  | x               |             |\n",
    "| 25     | 2      |                  | x               |             |\n",
    "| 30     | 1      |                  | x               |             |\n",
    "\n",
    "---\n",
    "\n",
    "##### Corte 3: precio ≤ 22.5\n",
    "\n",
    "- Grupo 1: [10, 15, 20] → media = 4.67  \n",
    "- Grupo 2: [25, 30] → media = 1.5  \n",
    "\n",
    "MSE = $\\frac{(6-4.67)^2 + (5-4.67)^2 + (3-4.67)^2 + (2-1.5)^2 + (1-1.5)^2}{5}$  \n",
    "MSE = $\\frac{1.76 + 0.11 + 2.78 + 0.25 + 0.25}{5} = \\mathbf{1.03}$\n",
    "\n",
    "| precio | ventas | grupo 1 (μ=4.67) | grupo 2 (μ=1.5) | MSE Corte 3 |\n",
    "|--------|--------|------------------|------------------|--------------|\n",
    "| 10     | 6      | x                |                  | 1.03         |\n",
    "| 15     | 5      | x                |                  |              |\n",
    "| 20     | 3      | x                |                  |              |\n",
    "| 25     | 2      |                  | x                |              |\n",
    "| 30     | 1      |                  | x                |              |\n",
    "\n",
    "---\n",
    "\n",
    "##### Corte 4: precio ≤ 27.5\n",
    "\n",
    "- Grupo 1: [10, 15, 20, 25] → media = 4  \n",
    "- Grupo 2: [30] → media = 1  \n",
    "\n",
    "MSE = $\\frac{(6-4)^2 + (5-4)^2 + (3-4)^2 + (2-4)^2 + (1-1)^2}{5}$  \n",
    "MSE = $\\frac{4 + 1 + 1 + 4 + 0}{5} = \\mathbf{2.0}$\n",
    "\n",
    "| precio | ventas | grupo 1 (μ=4) | grupo 2 (μ=1) | MSE Corte 4 |\n",
    "|--------|--------|---------------|---------------|-------------|\n",
    "| 10     | 6      | x             |               | 2.0         |\n",
    "| 15     | 5      | x             |               |             |\n",
    "| 20     | 3      | x             |               |             |\n",
    "| 25     | 2      | x             |               |             |\n",
    "| 30     | 1      |               | x             |             |\n",
    "\n",
    "---\n",
    "\n",
    "### Resultado:\n",
    "\n",
    "| Corte         | MSE   |\n",
    "|---------------|-------|\n",
    "| precio ≤ 12.5 | 1.75  |\n",
    "| precio ≤ 17.5 | 0.50  |\n",
    "| precio ≤ 22.5 | 1.03  |\n",
    "| precio ≤ 27.5 | 2.00  |\n",
    "\n",
    "Comparamos todos los cortes: \n",
    "\n",
    "> #### **Corte óptimo**: `precio ≤ 17.5`, con MSE = **0.50**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Entonces, ¿Qué hace el árbol de regresión?\n",
    "\n",
    "- Construye reglas jerárquicas que dividen el conjunto de datos según umbrales óptimos.\n",
    "- Por ejemplo, con el dataset:\n",
    "\n",
    "  | precio | ventas |\n",
    "  |--------|--------|\n",
    "  | 10     | 6      |\n",
    "  | 15     | 5      |\n",
    "  | 20     | 3      |\n",
    "  | 25     | 2      |\n",
    "  | 30     | 1      |\n",
    "\n",
    "Comparando posibles cortes sobre `precio`, el árbol evalúa los valores intermedios entre observaciones ordenadas:\n",
    "- Corte óptimo: `precio ≤ 17.5` → MSE total = **0.50**, el menor entre todos los candidatos.\n",
    "\n",
    "  El árbol puede construir reglas como:\n",
    "\n",
    ">  - Si `precio ≤ 17.5` → predicción ventas = 5.5  \n",
    ">  - Si `precio > 17.5` → predicción ventas = 2.0\n",
    "\n",
    "Cada regla define un nodo hoja (`leaf node`) en el que la predicción es el promedio de las observaciones en ese grupo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Calculemos el decision tree para la regresión anterior, a ver qué pasa con ventas! \n",
    "![](./model_outputs/reg_ventas.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Features y target\n",
    "X = df[[\n",
    "    'clicks', 'tiempo_browsing', 'paginas_visitadas', 'precio',\n",
    "    'descuento_pct', 'rating_promedio', 'edad', 'es_feriado', 'es_domingo',\n",
    "    'dia_semana', 'hora', 'dias_desde_promocion', 'logueado',\n",
    "    'codigo_promocional'\n",
    "]]\n",
    "y = df['ventas']\n",
    "\n",
    "# División en entrenamiento y testeo (80/20) >>> test_size=0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Árbol de regresión\n",
    "tree = DecisionTreeRegressor(max_depth=4, criterion='squared_error', random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# MSE\n",
    "y_pred_train = tree.predict(X_train)\n",
    "y_pred_test = tree.predict(X_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\n=== DECISION TREE REGRESIÓN ===\")\n",
    "print(f\"MSE entrenamiento: {mse_train:.4f}\")\n",
    "print(f\"MSE testeo:        {mse_test:.4f}\")\n",
    "\n",
    "# Visualización del árbol\n",
    "view_dectree(\n",
    "    tree_model=tree, \n",
    "    features=list(X.columns),\n",
    "    nombre_base='arbol_regresion_ventas', \n",
    "    horizontal_spacing=1.2,\n",
    "    vertical_spacing=1.2,\n",
    "    font_size=16,\n",
    "    flecha_grosor_factor=2,\n",
    "    min_leaf_pct=0.01\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n=== ÁRBOL DE DECISIÓN CON DETALLES ===\\n\")\n",
    "print(view_text_tree_detailed(tree, list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== PRUNED: ÁRBOL DE DECISIÓN CON DETALLES, sin nodos con menos del 5% de muestra ===\\n\")\n",
    "print(view_text_tree_pruned(tree, list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_sorted_tree_paths(tree, list(X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedimiento para interpretar el árbol de decisión respecto del precio\n",
    "\n",
    "\n",
    "## 1. Identificar las hojas con mayor valor esperado de ventas\n",
    "Localizar los nodos terminales (leaves) con mayores valores de value (predicción de ventas). Estos representan combinaciones de condiciones que conducen a mayor desempeño.\n",
    "\n",
    "## 2. Reconstruir el camino de decisión hacia esas hojas  \n",
    "Desde cada hoja seleccionada, recorrer hacia atrás el árbol hasta la raíz, recuperando las reglas (splits) que determinan esas predicciones.\n",
    "\n",
    "## 3. Filtrar en esos caminos los nodos donde aparece precio\n",
    "Enfocarse sólo en las ramas donde la variable precio participa activamente como criterio de división.\n",
    "\n",
    "## 4. Extraer los rangos de precios asociados a mayores ventas\n",
    "A partir de los cortes de precio en esos caminos, derivar los intervalos de precio que están vinculados con mayores ventas.\n",
    "\n",
    "## 5. Analizar las interacciones entre precio y otras variables en esas ramas\n",
    "Observar qué otras variables acompañan al precio en esas rutas (por ejemplo: paginas_visitadas, logueado, descuento_pct, etc.), y cómo la combinación de esos factores modifica el nivel de ventas.\n",
    "\n",
    "---\n",
    "\n",
    "Este análisis permite:\n",
    "\n",
    "- Inferir condiciones específicas de precio bajo las cuales las ventas aumentan\n",
    "- Detectar interacciones relevantes que un modelo lineal probablemente no captaría\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del árbol de decisión respecto a la variable `precio`\n",
    "\n",
    "(sólo hojas con N ≥ 0.5% del total)\n",
    "\n",
    "#### Paso 1: Hojas con mayor valor de ventas\n",
    "\n",
    "Se identifican las siguientes hojas con valores predichos más altos y soporte muestral:\n",
    "\n",
    "- 1.86 → paginas_visitadas > 5.5, precio > 19.28, hora > 1.5\n",
    "- 1.60 → paginas_visitadas > 5.5, logueado > 0.5, descuento_pct ≤ 38.25  \n",
    "- 1.58 → paginas_visitadas ≤ 5.5, logueado > 0.5, dia_semana > 4.5, precio > 25.05\n",
    "- 1.55 → paginas_visitadas > 5.5, logueado ≤ 0.5, edad > 37.33\n",
    "- 1.34 → paginas_visitadas ≤ 5.5, logueado > 0.5, dia_semana ≤ 4.5, precio > 17.02\n",
    "- 1.33 → paginas_visitadas > 5.5, logueado ≤ 0.5, edad ≤ 37.33\n",
    "- 1.26 → paginas_visitadas ≤ 5.5, logueado ≤ 0.5, rating_promedio > 2.53, precio > 13.09\n",
    "- 1.04 → paginas_visitadas ≤ 5.5, logueado > 0.5, dia_semana > 4.5, precio ≤ 25.05\n",
    "\n",
    "\n",
    "#### Paso 2: Presencia de `precio` como criterio de decisión\n",
    "\n",
    "La variable `precio` aparece como nodo de decisión en tres contextos estructurales del árbol:\n",
    "\n",
    "1. **Usuarios no logueados con pocas páginas visitadas** (`paginas_visitadas ≤ 5.5`, `logueado = 0`):  \n",
    "   - Si además tienen un `rating_promedio > 2.53`, se bifurca por `precio`.  \n",
    "     • Es decir, el modelo considera que, para estos usuarios, la combinación de nivel medio-alto de rating y no estar logueado requiere discriminar según `precio` para estimar las ventas.  \n",
    "   - En este subgrupo (rama):  \n",
    "     - si `precio > 13.09`, está asociado a ventas de **1.26**.  \n",
    "     - si `precio ≤ 13.09`, el valor predicho es **5.00**, pero esa hoja tiene **N = 1**, por lo que se considera no representativa.\n",
    "\n",
    "2. **Usuarios logueados con pocas páginas visitadas** (`paginas_visitadas ≤ 5.5`, `logueado = 1`):  \n",
    "   - En este segmento, el árbol primero distingue si es un día de semana (`dia_semana ≤ 4.5`) o fin de semana (`dia_semana > 4.5`).  \n",
    "     • Es decir, el modelo introduce el día como variable de contexto para determinar el rol del `precio` en la predicción.  \n",
    "   - En este subgrupo (rama):  \n",
    "     - en días hábiles, si `precio > 17.02`, se predicen ventas de **1.34**.  \n",
    "     - en fines de semana, si `precio > 25.05`, se predicen ventas de **1.58**; si `precio ≤ 25.05`, se predicen ventas de **1.04**.\n",
    "\n",
    "3. **Usuarios con muchas páginas visitadas** (`paginas_visitadas > 9.5`):  \n",
    "   - En este segmento, `precio` es el primer nodo de decisión.  \n",
    "     • Es decir, el modelo interpreta que, cuando un usuario navega muchas páginas, el valor del `precio` es el factor más relevante para estimar la probabilidad de compra.  \n",
    "   - En este subgrupo (rama):  \n",
    "     - si `precio > 19.28` y `hora > 1.5`, se predicen ventas de **1.86**, uno de los valores más altos del árbol con N significativo.  \n",
    "     - si `precio > 19.28` y `hora ≤ 1.5`, se predicen ventas de **2.64**, pero con N bajo (0.3%), por lo que se considera marginal.  \n",
    "     - si `precio ≤ 19.28`, el árbol bifurca según `descuento_pct`, pero las hojas con mayor predicción en este tramo (por ejemplo, **4.50**) tienen N < 0.5%, por lo que no se consideran confiables.\n",
    "\n",
    "### Paso 3: Rango de precios asociado a mayores ventas (con N ≥ 0.5%)\n",
    "\n",
    "- Cuando `precio > 19.28` y además `hora > 1.5`, se predicen ventas de **1.86**, el valor más alto con soporte muestral válido en todo el árbol.\n",
    "- En el segmento de usuarios logueados en días de semana, `precio > 17.02` está asociado a **1.34** ventas, mientras que valores menores o iguales conducen a hojas con N muy bajo (por ejemplo, 3.50 ventas con N = 4).\n",
    "- En el mismo grupo de usuarios logueados, pero en fines de semana, `precio > 25.05` se asocia a un leve incremento de ventas, alcanzando **1.58**, mientras que precios menores o iguales se relacionan con **1.04**.\n",
    "\n",
    "### Paso 4: Conjunciones más efectivas\n",
    "\n",
    "- `(precio > 17.02) AND (dia_semana ≤ 4.5)` → ventas de **1.34** en usuarios logueados entre semana; se trata de una hoja con alta representatividad (N = 2107).\n",
    "- `(precio > 25.05) AND (dia_semana > 4.5)` → ventas de **1.58** en usuarios logueados durante fines de semana.\n",
    "- `(precio > 13.09) AND (rating_promedio > 2.53)` → ventas de **1.26** en usuarios no logueados con pocas páginas y valoración media-alta; esta combinación define una subrama con N = 1970.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Predicción más alta o respaldo muestral?\n",
    "\n",
    "Cuando analizamos un árbol de decisión de regresión, muchas veces aparecen ramas que predicen valores altos pero con muy pocos casos (`N`), y otras que predicen valores más bajos pero con gran respaldo empírico. ¿Cuál debería guiar nuestras decisiones?\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "- **Predicted Value: 1.86**  \n",
    "  N: 255 casos (3.2%)  \n",
    "  → Alta predicción, bajo respaldo\n",
    "\n",
    "- **Predicted Value: 1.60**  \n",
    "  N: 1661 casos (20.8%)  \n",
    "  → Predicción más baja, alto respaldo\n",
    "\n",
    "#### ¿Cuál es mejor?\n",
    "\n",
    "Todo depende del objetivo de la recomendación. Hay tres formas posibles de evaluar cuál “domina”:\n",
    "\n",
    "---\n",
    "#### A. Maximizar la **predicción individual**\n",
    "\n",
    "> Se elige el valor más alto, sin importar el N.\n",
    "\n",
    "Este criterio sirve si el interés es identificar **casos con máximo potencial unitario**, aunque sean raros. Se recomienda con cautela porque el respaldo empírico puede ser débil.\n",
    "\n",
    "**Dominante**: Predicted Value = 1.86\n",
    "\n",
    "---\n",
    "\n",
    "#### B. Para maximizar el **volumen total esperado**\n",
    "\n",
    "> Se multiplica `Predicted × N` para obtener una estimación del impacto total.\n",
    "\n",
    "Calculamos:\n",
    "\n",
    "- 1.86 × 255 ≈ **474 unidades esperadas**\n",
    "- 1.60 × 1661 ≈ **2658 unidades esperadas**\n",
    "\n",
    "Aunque el valor predicho es menor, la segunda opción tiene mayor impacto acumulado por el tamaño del grupo.\n",
    "\n",
    "**Dominante**: Predicted Value = 1.60\n",
    "\n",
    "---\n",
    "\n",
    "#### C. Para obtener una recomendación **robusta y generalizable**\n",
    "\n",
    "> Se utiliza un umbral mínimo de N (por ejemplo, 0.5% del total)  \n",
    "> y dentro de ese conjunto, se ordenan por valor predicho.\n",
    "\n",
    "Esto evita tomar decisiones sobre combinaciones que casi no aparecen en los datos, y asegura confiabilidad estadística. Es el criterio más conservador y recomendado para automatizar decisiones.\n",
    "\n",
    "**Dominante**: la opción con mayor `predicted` entre las hojas con N ≥ 0.5%\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones de precios según comportamiento del usuario\n",
    "\n",
    "A partir del análisis del árbol de decisión entrenado sobre los datos de ventas, se identificaron patrones que combinan comportamiento de navegación, estado del usuario y precios. Los resultados muestran que las decisiones óptimas de precio dependen del perfil de usuario, la intensidad de su navegación y el contexto temporal. A continuación, se sistematizan los escenarios más representativos en función de esas combinaciones.\n",
    "\n",
    "---\n",
    "\n",
    "### Escenarios representativos con ventas altas (ventas ≥ 1.86, N ≥ 0.5%)\n",
    "\n",
    "#### 1. Precio alto en usuarios altamente comprometidos\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas > 5.5`\n",
    "  - `paginas_visitadas > 9.5`\n",
    "  - `precio > 19.28`\n",
    "  - `hora > 1.50`\n",
    "- **Ventas esperadas**: 1.86\n",
    "- **Relevancia muestral**: N = 255 (3.2%)\n",
    "- **Interpretación**: en usuarios muy activos, el precio deja de ser una barrera si el horario es fuera de la madrugada. Las ventas se mantienen incluso con precios relativamente altos.\n",
    "\n",
    "#### 2. Descuentos intermedios en usuarios comprometidos\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas > 5.5`\n",
    "  - `paginas_visitadas <= 9.5`\n",
    "  - `logueado == 1`\n",
    "  - `descuento_pct <= 38.25`\n",
    "- **Ventas esperadas**: 1.60\n",
    "- **Relevancia muestral**: N = 1661 (20.8%)\n",
    "- **Interpretación**: los descuentos no necesitan ser extremos. En usuarios activos y logueados, el descuento medio genera un efecto claro de conversión.\n",
    "\n",
    "#### 3. Precio alto en fines de semana logueados\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas <= 5.5`\n",
    "  - `logueado == 1`\n",
    "  - `dia_semana > 4.5`\n",
    "  - `precio > 25.05`\n",
    "- **Ventas esperadas**: 1.58\n",
    "- **Relevancia muestral**: N = 776 (9.7%)\n",
    "- **Interpretación**: durante fines de semana, los usuarios logueados pueden tolerar precios altos. La conversión se mantiene en niveles aceptables si hay fuerte presencia.\n",
    "\n",
    "#### 4. Adultos no logueados con navegación intermedia\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas > 5.5`\n",
    "  - `paginas_visitadas <= 9.5`\n",
    "  - `logueado == 0`\n",
    "  - `edad > 37.33`\n",
    "- **Ventas esperadas**: 1.55\n",
    "- **Relevancia muestral**: N = 343 (4.3%)\n",
    "- **Interpretación**: los adultos que no se loguean pero navegan bastante terminan comprando en niveles moderadamente altos. El precio no aparece explícitamente, lo que sugiere que no es barrera en este subgrupo.\n",
    "\n",
    "#### 5. Precio medio para logueados en semana\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas <= 5.5`\n",
    "  - `logueado == 1`\n",
    "  - `dia_semana <= 4.5`\n",
    "  - `precio > 17.02`\n",
    "- **Ventas esperadas**: 1.34\n",
    "- **Relevancia muestral**: N = 2107 (26.3%)\n",
    "- **Interpretación**: incluso con precios medios-altos, los usuarios logueados entre semana muestran buena tasa de conversión. Este es el segmento más estable y representativo.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones para política de precios\n",
    "\n",
    "- Las combinaciones más efectivas se concentran en usuarios activos, con navegación amplia o logueo.\n",
    "- El precio es un factor relevante, pero actúa de forma contextual: puede elevarse si otras variables indican alto engagement.\n",
    "- Los mejores resultados aparecen con precios moderados o intermedios (17 a 25) más que con mínimos.\n",
    "- Se sugiere aplicar **estrategias dinámicas de precios**, donde el modelo detecte señales de compromiso en tiempo real (páginas vistas, horario, tipo de usuario) y ajuste el precio ofertado para maximizar ventas sin necesidad de descuentos extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones de precios según comportamiento del usuario\n",
    "\n",
    "A partir del análisis del árbol de decisión entrenado sobre los datos de ventas, se identificaron patrones que combinan comportamiento de navegación, estado del usuario y precios. Los resultados muestran que las decisiones óptimas de precio dependen del perfil de usuario, la intensidad de su navegación y el contexto temporal. A continuación, se sistematizan los escenarios que presentan los valores de ventas más altos bajo distintas combinaciones de condiciones.\n",
    "\n",
    "---\n",
    "\n",
    "### Escenarios con valores predichos de ventas elevados (≥ 3.5)\n",
    "\n",
    "#### 1. Rating bajo, no logueado, pocas páginas\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas ≤ 5.5`\n",
    "  - `logueado == 0`\n",
    "  - `rating_promedio ≤ 2.53`\n",
    "  - `clicks ≤ 6.5`\n",
    "- **Precio considerado**: no interviene\n",
    "- **Ventas predichas**: 6.00\n",
    "- **Observación**: N=1 (0.0%) → no representativo\n",
    "\n",
    "#### 2. Rating alto, no logueado, precio bajo\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas ≤ 5.5`\n",
    "  - `logueado == 0`\n",
    "  - `rating_promedio > 2.53`\n",
    "  - `precio ≤ 13.09`\n",
    "- **Ventas predichas**: 5.00\n",
    "- **Observación**: N=1 (0.0%) → no representativo\n",
    "\n",
    "#### 3. Usuario logueado en días hábiles, precio moderado\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas ≤ 5.5`\n",
    "  - `logueado == 1`\n",
    "  - `dia_semana ≤ 4.5`\n",
    "  - `precio ≤ 17.02`\n",
    "- **Ventas predichas**: 3.50\n",
    "- **Observación**: N=4 (0.1%) → marginalmente representativo\n",
    "\n",
    "#### 4. Descuentos agresivos con navegación intermedia\n",
    "- **Condiciones**:\n",
    "  - `5.5 < paginas_visitadas ≤ 9.5`\n",
    "  - `logueado == 1`\n",
    "  - `descuento_pct > 38.25`\n",
    "- **Ventas predichas**: 3.60\n",
    "- **Observación**: N=5 (0.1%) → marginalmente representativo\n",
    "\n",
    "#### 5. Navegación intensiva con descuento moderado\n",
    "- **Condiciones**:\n",
    "  - `paginas_visitadas > 9.5`\n",
    "  - `precio ≤ 19.28`\n",
    "  - `descuento_pct > 20.15`\n",
    "- **Ventas predichas**: 4.50\n",
    "- **Observación**: N=2 (0.0%) → no representativo\n",
    "\n",
    "---\n",
    "\n",
    "### Política de precios\n",
    "\n",
    "- Las predicciones más altas de ventas ocurren bajo condiciones particulares de navegación, estado del usuario y descuentos, y no pueden atribuirse de forma directa al precio de forma aislada.\n",
    "- El **precio no es determinante lineal ni autónomo**: su influencia depende del contexto y del perfil del usuario. \n",
    "- **Valores altos de precio (superiores a 25)** no están asociados a mayores niveles de ventas, incluso cuando el usuario está logueado o en días no laborables.\n",
    "- Se recomienda implementar **estrategias de precios diferenciadas**, ajustadas a señales de comportamiento como navegación activa, estado de sesión (logueado o no), nivel de rating promedio, y momento temporal (día de la semana, hora).\n",
    "- Las hojas con mayor valor predicho no tienen respaldo empírico suficiente (N < 0.5%), por lo que **no deben ser consideradas como evidencia sólida**, aunque pueden guiar hipótesis de testeo futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siguiendo la misma lógica, podemos hacer la interpretación general del árbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación general del árbol de decisión\n",
    "\n",
    "El árbol de decisión genera reglas jerárquicas para predecir el número de ventas (`ventas`) mediante divisiones sucesivas basadas en variables explicativas. Cada nodo intermedio representa una condición binaria sobre una variable, y cada nodo hoja indica una predicción promedio de ventas para un subconjunto específico de usuarios. La variable `paginas_visitadas` funciona como nodo raíz, dividiendo el árbol en dos grandes ramas: usuarios de baja navegación (≤ 5.5) y usuarios con navegación más intensiva (> 5.5).\n",
    "\n",
    "---\n",
    "\n",
    "### Subárbol izquierdo: usuarios con navegación baja (paginas_visitadas ≤ 5.5)\n",
    "\n",
    "#### Usuarios no logueados (`logueado ≤ 0.5`)\n",
    "- Si `rating_promedio ≤ 2.53`:\n",
    "  - Si `clicks ≤ 6.5`: **ventas = 6.00**, pero con N=1 → no representativo\n",
    "  - Si `clicks > 6.5`: **ventas = 2.00**, también con N=1 → no representativo\n",
    "- Si `rating_promedio > 2.53`:\n",
    "  - Si `precio ≤ 13.09`: **ventas = 5.00**, N=1 → no representativo\n",
    "  - Si `precio > 13.09`: **ventas = 1.26**, N=1970 (24.6%) → representativo\n",
    "\n",
    "#### Usuarios logueados (`logueado > 0.5`)\n",
    "- Si `dia_semana ≤ 4.5` (días hábiles):\n",
    "  - Si `precio ≤ 17.02`: **ventas = 3.50**, N=4 (0.1%) → marginalmente representativo\n",
    "  - Si `precio > 17.02`: **ventas = 1.34**, N=2107 (26.3%) → representativo\n",
    "- Si `dia_semana > 4.5` (fin de semana):\n",
    "  - Si `precio ≤ 25.05`: **ventas = 1.04**, N=67 (0.8%)\n",
    "  - Si `precio > 25.05`: **ventas = 1.58**, N=776 (9.7%)\n",
    "\n",
    "---\n",
    "\n",
    "### Subárbol derecho: usuarios con navegación media o alta (paginas_visitadas > 5.5)\n",
    "\n",
    "#### Visitas medias (paginas_visitadas ≤ 9.5)\n",
    "\n",
    "- Si `logueado ≤ 0.5`:\n",
    "  - Si `edad ≤ 37.33`: **ventas = 1.33**, N=782 (9.8%)\n",
    "  - Si `edad > 37.33`: **ventas = 1.55**, N=343 (4.3%)\n",
    "\n",
    "- Si `logueado > 0.5`:\n",
    "  - Si `descuento_pct ≤ 38.25`: **ventas = 1.60**, N=1661 (20.8%)\n",
    "  - Si `descuento_pct > 38.25`: **ventas = 3.60**, N=5 (0.1%) → marginalmente representativo\n",
    "\n",
    "#### Visitas intensas (paginas_visitadas > 9.5)\n",
    "\n",
    "- Si `precio ≤ 19.28`:\n",
    "  - Si `descuento_pct ≤ 20.15`: **ventas = 3.00**, N=3 → no representativo\n",
    "  - Si `descuento_pct > 20.15`: **ventas = 4.50**, N=2 → no representativo\n",
    "\n",
    "- Si `precio > 19.28`:\n",
    "  - Si `hora ≤ 1.50`: **ventas = 2.64**, N=22 (0.3%)\n",
    "  - Si `hora > 1.50`: **ventas = 1.86**, N=255 (3.2%)\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones clave\n",
    "\n",
    "- Las predicciones más altas del árbol se producen en subgrupos con baja evidencia empírica (N ≤ 1), lo que limita su valor para recomendaciones prácticas.\n",
    "- Entre los escenarios representativos (N ≥ 0.5%), los valores de ventas se concentran entre 1.04 y 1.86.\n",
    "- El precio actúa de manera **condicional**: no es un factor determinante por sí mismo, sino que su efecto depende de otras variables como el rating, el logueo o el día de la semana.\n",
    "- El árbol identifica configuraciones no lineales y no aditivas: por ejemplo, el mismo precio puede ser favorable o desfavorable según la hora o el tipo de usuario.\n",
    "- La estructura permite captar perfiles de comportamiento diferenciados (ej. logueados entre semana, no logueados con buen rating, usuarios intensivos con descuentos), lo cual excede las capacidades de un modelo lineal estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable                    | Regresión Temporal | Regresión Extendida | Árbol de Decisión                         | Interacción estructural en árbol                                   |\n",
    "|----------------------------|--------------------|---------------------|-------------------------------------------|--------------------------------------------------------------------|\n",
    "| **Intercepto**             | 0.9390***          | 0.5838**            | -                                         | -                                                                  |\n",
    "| Clicks                     | -0.0095            | -0.0098             | Condición terminal (nivel 3, N bajo)      | en usuarios no logueados con navegación baja y rating bajo         |\n",
    "| Tiempo_Browsing            | 0.0005**           | 0.0005**            | Condición intermedia (nivel 3, N bajo)    | en usuarios no logueados con navegación baja y rating bajo         |\n",
    "| Paginas_Visitadas          | 0.0556***          | 0.0551***           | Variable de segmentación raíz (nivel 0)   | todas las ramas (nivel raíz)                                       |\n",
    "| Feriado                    | 0.0164             | 0.0180              | -                                         | -                                                                  |\n",
    "| Domingo                    | 0.1659***          | 0.1609***           | Condición intermedia (nivel 2)            | en usuarios logueados con navegación baja                          |\n",
    "| Dia_Semana                 | 0.0046             | 0.0057              | Condición intermedia (nivel 2)            | en usuarios logueados con navegación baja                          |\n",
    "| Hora                       | 0.0039**           | 0.0038**            | Condición terminal (nivel 4)              | en usuarios con navegación alta y precios altos                    |\n",
    "| Dias_Desde_Promocion       | 0.0020             | 0.0019              | -                                         | -                                                                  |\n",
    "| Logueado                   | 0.1213***          | 0.1229***           | Condición estructurante (nivel 1)         | divide navegación baja y navegación media/alta                     |\n",
    "| Codigo_Promocional         | 0.1673***          | 0.1637***           | Condición terminal (nivel 4)              | en usuarios logueados con navegación media                         |\n",
    "| Precio                     | —                  | -0.0002             | Condición intermedia (niveles 2–3)        | aparece en múltiples ramas: rating alto, logueados, usuarios activos |\n",
    "| Descuento                  | —                  | -0.0022             | Condición intermedia (niveles 2–3)        | en usuarios con navegación media y alta                            |\n",
    "| Rating                     | —                  | 0.0989**            | Condición estructurante (nivel 1)         | en usuarios no logueados con navegación baja                       |\n",
    "| Edad                       | —                  | -0.0013             | Condición terminal (nivel 4)              | en usuarios no logueados con navegación media                      |\n",
    "| curso_Finanzas             | —                  | -0.0463             | -                                         | -                                                                  |\n",
    "| curso_Liderazgo            | —                  | -0.0093             | -                                         | -                                                                  |\n",
    "| nivel_Inicial              | —                  | 0.1062              | -                                         | -                                                                  |\n",
    "| nivel_Intermedio           | —                  | 0.0576              | -                                         | -                                                                  |\n",
    "| dispositivo_PC             | —                  | 0.1548***           | -                                         | -                                                                  |\n",
    "| referrer_competencia       | —                  | -0.0222             | -                                         | -                                                                  |\n",
    "| referrer_correo            | —                  | 0.0858**            | -                                         | -                                                                  |\n",
    "| referrer_otros             | —                  | -0.0090             | -                                         | -                                                                  |\n",
    "| referrer_redes             | —                  | 0.0180              | -                                         | -                                                                  |\n",
    "| referrer_youtube           | —                  | 0.0918**            | -                                         | -                                                                  |\n",
    "| nivel_educativo_Secundario| —                  | -0.1216***          | -                                         | -                                                                  |\n",
    "| nivel_educativo_Terciario | —                  | -0.1515***          | -                                         | -                                                                  |\n",
    "| nivel_educativo_Universit.| —                  | -0.0577             | -                                         | -                                                                  |\n",
    "\n",
    "---\n",
    "\n",
    "### Notas sobre el árbol de decisión:\n",
    "\n",
    "- **Clicks** y **Tiempo_Browsing**: sólo aparecen como nodos finales en una rama poco representativa (usuarios no logueados, baja navegación, rating bajo).\n",
    "- **Paginas_Visitadas**: define la raíz y estructura principal del árbol; divide entre baja, media y alta navegación.\n",
    "- **Logueado**: actúa como variable clave que segmenta comportamiento y sensibilidad al precio y descuentos.\n",
    "- **Precio**: relevante pero no determinante por sí solo. Su impacto depende del día, el logueo o el nivel de rating.\n",
    "- **Descuento**: efectivo solo en ramas de usuarios activos o logueados, condicionado por el precio o el número de páginas vistas.\n",
    "- **Edad**: utilizada para discriminar dentro de no logueados con navegación intermedia; su efecto es marginal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Categoría técnica                      | Definición específica                                                                 |\n",
    "|---------------------------------------|----------------------------------------------------------------------------------------|\n",
    "| **Variable de Segmentación Raíz**     | Variable utilizada en el primer nivel del árbol para dividir el conjunto (nivel 0).   |\n",
    "| **Condición Estructurante**           | Variable ubicada en el segundo nivel del árbol (nivel 1), estructura grandes ramas.   |\n",
    "| **Condición Intermedia**              | Variable ubicada en niveles medios (nivel 2 o 3), refina subdivisiones parciales.     |\n",
    "| **Criterio Final de Decisión**        | Variable que aparece en las hojas (nivel 4), determina valores predichos finales.     |\n",
    "| **Variable estructural**              | Cualquier variable que participa en al menos una partición dentro del árbol.          |\n",
    "| **No utilizada**                      | Variable que no participa en ninguna división del árbol de decisión.                  |\n",
    "\n",
    "\n",
    "\n",
    "### Jerarquía y relaciones entre categorías\n",
    "\n",
    "- **Variable estructural** es la categoría más amplia: agrupa todas las variables que participan en algún punto del árbol.\n",
    "- Las subcategorías (**Variable de Segmentación Raíz**, **Condición Estructurante**, **Condición Intermedia**, **Criterio Final de Decisión**) son **mutuamente excluyentes** y se definen por el **nivel más superficial** en el cual aparece la variable:\n",
    "  - Variable de Segmentación Raíz → nivel 0  \n",
    "  - Condición Estructurante → nivel 1  \n",
    "  - Condición Intermedia → niveles 2–3  \n",
    "  - Criterio Final de Decisión → nivel 4\n",
    "- Una variable no puede ocupar más de una subcategoría: se clasifica según su primer nivel de aparición."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Síntesis comparativa de enfoques: regresiones lineales vs árbol de decisión\n",
    "\n",
    "- **Las regresiones OLS** permiten estimar efectos marginales promedio y cuantificar la significación estadística de cada variable bajo un modelo aditivo. Son especialmente útiles para interpretar el peso de factores como `logueado`, `codigo_promocional`, `paginas_visitadas` o `domingo`, todos ellos con coeficientes significativos y estables.\n",
    "\n",
    "- **El árbol de decisión**, en cambio, permite capturar relaciones no lineales, interacciones jerárquicas y puntos de quiebre. Variables como `paginas_visitadas`, `logueado`, `precio` y `rating_promedio`, que en la regresión no destacan por igual, emergen como criterios de división centrales en el árbol.\n",
    "\n",
    "- La combinación de ambos enfoques revela:\n",
    "  - Efectos lineales y globales (OLS)\n",
    "  - Segmentaciones locales y umbrales decisivos (árbol)\n",
    "  - Importancia contextual de variables que, según el modelo, pueden parecer irrelevantes si se observan de forma aislada\n",
    "\n",
    "**Entonces**: modelar requiere abordar tanto relaciones promedio como estructuras condicionales. Usar solo una técnica puede ocultar patrones relevantes. La complementariedad entre métodos mejora tanto la capacidad explicativa como la robustez analítica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Qué hacer? ACCIONES basadas en el árbol de decisión y los modelos de regresión\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Las decisiones óptimas deben alinearse con los patrones revelados en el árbol: no existen efectos universales de precio o descuento, sino reglas condicionadas por el comportamiento y estado del usuario. La regresión aporta señales de dirección general, pero es el árbol el que estructura las acciones. A continuación, se sistematizan las recomendaciones según los segmentos principales.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Segmentar la estrategia en función de `paginas_visitadas`**\n",
    "\n",
    "Esta variable aparece como raíz del árbol y organiza todo el flujo de decisión. Permite distinguir tres perfiles claramente diferenciados en términos de compromiso y respuesta:\n",
    "\n",
    "#### a. **Usuarios con navegación baja (`paginas_visitadas ≤ 5.5`)**\n",
    "\n",
    "- **Perfil**: primera visita, poca exploración, alto abandono si no hay impacto inmediato.\n",
    "- **Acción**: mostrar beneficios de forma inmediata, en la primera pantalla. Usar testimonios, estrellas, beneficios visuales.\n",
    "- **Evidencia**:\n",
    "  - Si no están logueados y el rating es bajo, hay una hoja con predicción 6.00, pero con N = 1.\n",
    "  - Si no están logueados y el rating es alto, un precio bajo (≤ 13.09) lleva a predicción 5.00, pero nuevamente N = 1.\n",
    "  - Si están logueados, los días de semana y precios moderados (≤ 17.02) generan ventas de 3.50 (aunque N = 4).\n",
    "- **Conclusión**: hay combinaciones que predicen mucho, pero no tienen respaldo muestral. Deben usarse con precaución. El precio solo ayuda si hay señales positivas (rating alto, logueo, día hábil).\n",
    "\n",
    "#### b. **Usuarios con navegación intermedia (`5.5 < paginas_visitadas ≤ 9.5`)**\n",
    "\n",
    "- **Perfil**: muestran cierto interés pero no alcanzan niveles intensos de exploración. Segmento más representativo en tamaño.\n",
    "- **Acción**: diferenciar según si están logueados y según edad.\n",
    "- **Evidencia**:\n",
    "  - No logueados: los más jóvenes (≤ 37.33) responden un poco mejor (1.33 vs. 1.55).\n",
    "  - Logueados con descuentos bajos (≤ 38.25): predicción 1.60 con N alto (1661).\n",
    "  - Logueados con descuentos altos: sube a 3.60, pero con N = 5.\n",
    "- **Conclusión**: el descuento tiene efecto sólo cuando hay login. Sin login, la segmentación por edad tiene efectos menores. Los descuentos agresivos deben reservarse para usuarios comprometidos.\n",
    "\n",
    "#### c. **Usuarios con navegación alta (`paginas_visitadas > 9.5`)**\n",
    "\n",
    "- **Perfil**: muy activos, muestran fuerte interés.\n",
    "- **Acción**: aplicar precios moderados y mostrar descuentos sólo si hay evidencia de interés en horarios específicos.\n",
    "- **Evidencia**:\n",
    "  - Si `precio ≤ 19.28` y `descuento > 20.15`: predicción 4.50 (N = 2).\n",
    "  - Si `precio > 19.28` y `hora > 1.5`: predicción 1.86 con N = 255.\n",
    "- **Conclusión**: este es el segmento más sensible a combinaciones entre horario y precio. Las reglas son específicas y de aplicación precisa.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **No aplicar descuentos universales**\n",
    "\n",
    "- **Árbol**: el `descuento` solo mejora ventas cuando se combina con navegación media-alta y login. \n",
    "- **Regresión**: coeficiente negativo (-0.0022), lo que indica que en promedio el efecto es negativo.\n",
    "- **Acción**: restringir promociones fuertes a quienes ya hayan dado señales de interés (páginas vistas, login).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Evitar confiar en precios bajos como estrategia general**\n",
    "\n",
    "- **Árbol**: el `precio` sólo mejora predicciones en contextos acotados (por ejemplo, usuarios no logueados con rating alto).\n",
    "- **Regresión**: el coeficiente de `precio` es estadísticamente irrelevante.\n",
    "- **Acción**: utilizar precios bajos solo si otras señales acompañan. No asumir que bajar precios aumenta ventas.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Aprovechar el login como condición estructurante**\n",
    "\n",
    "- Aparece como segunda decisión más importante en el árbol (nivel 1).\n",
    "- En la regresión tiene un coeficiente positivo y significativo (+0.1229).\n",
    "- Estructura la forma en que operan otras variables: día, descuento, precio, edad.\n",
    "- **Acción**: priorizar a usuarios logueados para acciones personalizadas, promociones y precios dinámicos.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](./aux/recomendaciones.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cruzar modelos: usar árbol y regresión estadística como complementos**\n",
    "\n",
    "- **El árbol** detecta combinaciones jerárquicas que predicen mejor en segmentos específicos.\n",
    "- **La regresión** captura efectos promedio que operan a nivel global.\n",
    "- **Ejemplo**:\n",
    "  - `edad` tiene un papel decisivo en el árbol bajo ciertas condiciones (no logueados), pero no es significativa en la regresión.\n",
    "  - `clicks` no aparece en la regresión pero en el árbol define rutas con valores extremos (aunque con N bajo).\n",
    "- **Acción**: combinar ambas fuentes para no sobreinterpretar reglas con baja representatividad, ni descartar efectos relevantes por estar diluidos en promedios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Categorical Decision Trees: cómo, cuándo y dónde? Por qué?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de Árboles de Decisión: MSE, Entropía y Gini\n",
    "\n",
    "Los árboles de decisión pueden optimizar distintos criterios según el tipo de problema:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Árbol de Regresión** (`criterion='squared_error'` o `MSE`)\n",
    "- **Objetivo**: predecir una variable continua minimizando el **Error Cuadrático Medio (MSE)** en cada partición.\n",
    "- **Funcionamiento**: en cada división, se busca el umbral que genere subconjuntos que minimicen la varianza de la variable dependiente.\n",
    "- **Interpretación**: útil para capturar valores puntuales, con cortes más sensibles a valores extremos.\n",
    "- **Ventaja**: alta precisión cuando se necesita modelar una variable numérica continua.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Árbol de Clasificación**\n",
    "\n",
    "##### **(Entropía)** (`criterion='entropy'`)\n",
    "- **Objetivo**: clasificar en categorías minimizando la **entropía de Shannon**, es decir, maximizando la pureza informativa de los nodos.\n",
    "- **Funcionamiento**: mide la impureza como la cantidad de información (bits) necesaria para codificar una clase. Se elige el corte que más reduzca la incertidumbre.\n",
    "- **Interpretación**: útil cuando se desea entender la estructura jerárquica de decisiones con alta precisión teórica.\n",
    "- **Ventaja**: más sensible que Gini a diferencias pequeñas entre clases.\n",
    "\n",
    "##### **(Gini)** (`criterion='gini'`)\n",
    "- **Objetivo**: clasificar en categorías minimizando el **índice de Gini**, que mide la probabilidad de clasificación incorrecta.\n",
    "- **Funcionamiento**: en cada corte se busca maximizar la pureza de los subconjuntos respecto a una clase dominante.\n",
    "- **Interpretación**: favorece divisiones que agrupan de forma más homogénea.\n",
    "- **Ventaja**: computacionalmente más eficiente que la entropía y da resultados similares en muchos casos.\n",
    "\n",
    "\n",
    "\n",
    "#### Primera aproximación a diferencias clave\n",
    "\n",
    "| Criterio   | Tipo de Variable | Métrica           | Sensibilidad a clases | Enfoque principal        |\n",
    "|------------|------------------|--------------------|------------------------|--------------------------|\n",
    "| MSE        | Continua          | Varianza           | No aplica              | Precisión numérica       |\n",
    "| Entropía   | Categórica        | Información (Information Gain)       | Alta                   | Pureza informativa       |\n",
    "| Gini       | Categórica        | Impureza estadística| Moderada              | Dominancia de clase      |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Comparación técnica de criterios de partición en árboles de decisión\n",
    "\n",
    "| Criterio     | Tipo de Variable  | Fórmula matemática                                                                                     | Naturaleza        | Sensibilidad a clases | Interpretación técnica                                         |\n",
    "|--------------|-------------------|----------------------------------------------------------------------------------------------------------|--------------------|------------------------|----------------------------------------------------------------|\n",
    "| **MSE**      | Continua           | $ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\bar{y})^2 $                                             | Error cuadrático   | No aplica              | Mide la varianza dentro de los nodos. Menor MSE implica mayor homogeneidad numérica. Ideal para regresión. |\n",
    "| **Entropía** | Categórica         | $ H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i) $                                                             | Logarítmica        | Alta                   | Mide la incertidumbre del sistema. Penaliza más la mezcla de clases. Tiende a árboles más profundos.        |\n",
    "| **Gini**     | Categórica         | $ G(S) = 1 - \\sum_{i=1}^{c} p_i^2 $                                                                    | Cuadrática         | Moderada               | Mide la impureza. Es computacionalmente más simple que la entropía. Favorece clases dominantes.            |\n",
    "\n",
    "\n",
    "#### Donde:\n",
    "\n",
    "- $ p_i $: proporción de elementos de la clase $ i $ en el nodo.\n",
    "- $ c $: número total de clases posibles.\n",
    "- $ y_i $: valor observado.\n",
    "- $ \\bar{y} $: promedio de valores del nodo.\n",
    "\n",
    "---\n",
    "\n",
    "#### Consideraciones prácticas\n",
    "\n",
    "- **MSE**:\n",
    "  - Se usa exclusivamente en árboles de **regresión** con VARIABLE CONTINUA.\n",
    "  - Busca reducir la varianza intra-nodo.\n",
    "  - Cortes tienden a sobreajustarse si hay valores extremos.\n",
    "\n",
    "---\n",
    "\n",
    "- Los trees DE CLASIFICACIÓN sea con criterios de **entropía o gini**, se usan con variables DISCRETAS (0-1, o ALTO, MEDIO, BAJO; etc.):\n",
    "    - **Entropía**:\n",
    "        - Se usa en **clasificación**, priorizando máxima ganancia informativa.\n",
    "        - Es más sensible a distribuciones desbalanceadas.\n",
    "        - Tiene mayor coste computacional por el logaritmo.\n",
    "\n",
    "    - **Gini**:\n",
    "        - Alternativa a la entropía, más eficiente.\n",
    "        - Suaviza el efecto de clases raras.\n",
    "        - Prefiere divisiones con una clase claramente mayoritaria.\n",
    "\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué hace un Árbol de Clasificación?\n",
    "\n",
    "- Es un algoritmo que predice categorías (valores discretos) mediante divisiones sucesivas del espacio de datos.\n",
    "- En cada división (split), se elige la variable y el umbral que maximiza la \"pureza\" de los grupos.\n",
    "- Para eso se usan métricas como `entropía` o `índice Gini`, que indican qué tan mezcladas están las clases.\n",
    "- El resultado es una estructura de árbol con reglas condicionales que separan mejor las clases, rama por rama.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cómo se mide la pureza de un nodo?\n",
    "\n",
    "Se utiliza una métrica de impureza. La más común es la `entropía`, definida como:\n",
    "\n",
    "$$\n",
    "\\text{Entropía o H(S)} = -\\sum_{i} p_i \\cdot \\log_2(p_i)\n",
    "$$\n",
    "\n",
    "Donde $ p_i $ es la proporción de elementos de la clase $ i $ en el nodo. $H(S)$ se lee en unidades \"bits\". Cero bits: evento seguro, muchos bits: evento raro. A más bits, más inesperado en el evento. \n",
    "\n",
    "- Si un nodo tiene sólo una clase → entropía = 0 → nodo completamente puro.\n",
    "- Si hay mezcla de clases → entropía > 0 → nodo impuro.\n",
    "- El árbol busca dividir los datos en nodos con la menor entropía total posible.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Qué representa cada componente?\n",
    "\n",
    "- $ p_i $: es la **proporción** (o probabilidad) de la clase `i` en el nodo.\n",
    "- $ \\log_2(p_i) $: mide cuánta **información** aporta un evento si ocurre la clase `i`. Es negativa (porque $ p_i < 1 $) y su valor absoluto es mayor cuando la clase es más improbable.\n",
    "- El producto $ p_i \\cdot \\log_2(p_i) $ mide la \"información promedio esperada\" para una clase. Al sumar todos, se obtiene la incertidumbre total del nodo.\n",
    "\n",
    "> El logaritmo aparece porque en teoría de la información, la cantidad de información de un evento con probabilidad $p$ es $-\\log_2(p)$. Cuanto más improbable es el evento, más información genera al ocurrir.\n",
    "\n",
    "---\n",
    "\n",
    "##### ¿Por qué se multiplica por $ \\log_2(p_i) $?\n",
    "\n",
    "$\\log_2()$ es una función que transforma la probabilidad en una medida de información, indicando formalmente cuán \"inesperado\" o \"raro\" es que ocurra un evento de probabilidad $p$:\n",
    "\n",
    "- Si $p_A = 1$, el evento es seguro → $\\log_2(1) = 0$ → no aporta información. Es decir, no es raro que pase \"A\".\n",
    "- Si $p_B = 0.5$, el evento es incierto → $\\log_2(0.5) = -1$ → aporta 1 bit de información. Es decir, \"B\" es raro la mitad de las veces.\n",
    "- Si $p_B = 0.25$, el evento es más raro → $\\log_2(0.25) = -2$ → aporta 2 bits. Más inesperado el evento, más bits.\n",
    "- Si $p_B = 0.1$, el evento es muy raro → $\\log_2(0.1) \\approx -3.32$ → aporta más de 3 bits. Es decir, es muy raro que pase \"B\".\n",
    "\n",
    "$$ H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i) $$         \n",
    "\n",
    "    Nota: por eso el signo negativo al inicio de la fórmula, ya que la transformación log_2 devuelve valores negativos. La interpretación es absoluta. \n",
    "\n",
    "##### ¿Por qué se multiplica por $ p_i $?\n",
    "\n",
    "Porque buscamos una media ponderada: el valor esperado de la sorpresa que representa cada clase, en función de su probabilidad. Nos interesa saber cuánta información \"trae\" en promedio un caso aleatorio de ese nodo.\n",
    "\n",
    "<center> <h2><b>La entropía mide cuán mezcladas están las clases en un conjunto de datos</b></h2></center>\n",
    "\n",
    "---\n",
    "\n",
    "### Ejemplo con tres clases (`A`, `B`, `C`)\n",
    "\n",
    "| precio | clase |\n",
    "|--------|-------|\n",
    "| 10     | A     |\n",
    "| 15     | A     |\n",
    "| 20     | B     |\n",
    "| 25     | B     |\n",
    "| 30     | C     |\n",
    "\n",
    "Queremos encontrar el mejor punto de corte en la variable `precio`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Corte: `precio ≤ 17.5`\n",
    "\n",
    "- Grupo 1: [10, 15] → clases: A, A  \n",
    "  - $ p_A = 1.0 $  \n",
    "  - Entropía = $ -1 \\cdot \\log_2(1) = 0.0 $\n",
    "\n",
    "- Grupo 2: [20, 25, 30] → clases: B, B, C  \n",
    "  - $ p_B = 2/3,\\ p_C = 1/3 $  \n",
    "  - Entropía = $ -\\left( \\frac{2}{3} \\log_2 \\frac{2}{3} + \\frac{1}{3} \\log_2 \\frac{1}{3} \\right) ≈ 0.918 $\n",
    "\n",
    "**Entropía total (ponderada):**\n",
    "\n",
    "$$\n",
    "\\text{Entropía total} = \\frac{2}{5} \\cdot 0 + \\frac{3}{5} \\cdot 0.918 = 0.551\n",
    "$$\n",
    "\n",
    "> Este valor se compara con los de otros cortes para seleccionar el óptimo.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Qué pasa en casos extremos?\n",
    "\n",
    "- Si el nodo tiene 100% de clase A:  \n",
    "  $$\n",
    "  \\text{Entropía} = -1 \\cdot \\log_2(1) = 0\n",
    "  $$\n",
    "\n",
    "- Si las clases están perfectamente balanceadas, por ejemplo 50% A y 50% B:  \n",
    "  $$\n",
    "  \\text{Entropía} = -0.5 \\log_2(0.5) - 0.5 \\log_2(0.5) = 1\n",
    "  $$\n",
    "\n",
    "- Si hay 80% A y 20% B:  \n",
    "  $$\n",
    "  \\text{Entropía} = -0.8 \\log_2(0.8) - 0.2 \\log_2(0.2) ≈ 0.7219\n",
    "  $$\n",
    "\n",
    "> A medida que las clases se desbalancean, la entropía baja: el nodo es más predecible.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones del ejemplo con clases `A`, `B`, `C`\n",
    "\n",
    "1. **La entropía sirve para evaluar cortes, no para predecir clases.**\n",
    "   - En este ejemplo, el objetivo no es asignar una clase aún, sino decidir cómo dividir los datos para que los grupos resultantes sean lo más homogéneos posible.\n",
    "\n",
    "2. **El corte `precio ≤ 17.5` separa perfectamente a los casos de clase `A`.**\n",
    "   - El grupo 1 (precio ≤ 17.5) contiene sólo casos de clase `A`, por lo tanto su entropía es `0.0`. Es un grupo completamente puro.\n",
    "   - El grupo 2 contiene una mezcla de `B` y `C`, lo que genera una entropía positiva (≈ 0.918).\n",
    "\n",
    "3. **La entropía total del corte (0.551) refleja la mezcla residual en los grupos.**\n",
    "   - Es un promedio ponderado de las entropías de los grupos según su tamaño relativo.\n",
    "   - Esta entropía total representa la calidad de la división: cuanto más baja, mejor.\n",
    "   - *El corte `precio ≤ 17.5` tiene entropía de $0.551$ bits. \n",
    "\n",
    "4. **Comparamos entre todos los cortes posibles para seleccionar el óptimo.**\n",
    "   - En este ejemplo, si los demás cortes (como 22.5 o 27.5) tuvieran entropías totales mayores que 0.551, entonces `precio ≤ 17.5` sería el mejor split.\n",
    "\n",
    "5. **La entropía indica cuán predictivo será un nodo hoja, pero no es la predicción.**\n",
    "   - En el grupo 1, donde la entropía es cero, sabemos con certeza que cualquier nuevo dato que caiga allí será de clase `A`.\n",
    "   - En el grupo 2, aunque no es puro, el modelo aún puede asignar una clase mayoritaria (`B`) como predicción, pero con cierta incertidumbre.\n",
    "\n",
    "6. **Casos extremos ilustran el comportamiento de la entropía:**\n",
    "   - La entropía mínima es siempre `0` y ocurre cuando todos los casos en el nodo pertenecen a una sola clase (máxima pureza).\n",
    "   - La entropía máxima depende del número total de clases `k`, y se alcanza cuando todas las clases están presentes en proporciones iguales:\n",
    "     \n",
    "     $$\n",
    "     \\text{Entropía}_\\text{máx} = \\log_2(k)\n",
    "     $$\n",
    "\n",
    "      Por ejemplo:\n",
    "      - Con 2 clases: $\\log_2(2) = 1$\n",
    "      - Con 3 clases: $\\log_2(3) ≈ 1.585$\n",
    "      - Con 4 clases: $\\log_2(4) = 2$\n",
    "      - Con 10 clases: $\\log_2(10) ≈ 3.322$\n",
    "\n",
    "   - Valores intermedios reflejan distintos grados de mezcla: a mayor desbalance entre clases, menor entropía → mayor certeza predictiva.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Aplicación real: clasificación de `ventas_cat`\n",
    "\n",
    "Supongamos que discretizamos las ventas reales en tres clases:\n",
    "\n",
    "- `nada` (ventas = 0)\n",
    "- `una` (ventas = 1)\n",
    "- `mas_de_una` (ventas > 1)\n",
    "\n",
    "Usamos la variable `precio` para intentar dividir los datos.\n",
    "\n",
    "| precio | ventas_cat  |\n",
    "|--------|-------------|\n",
    "| 18     | nada        |\n",
    "| 21     | mas_de_una  |\n",
    "| 24     | nada        |\n",
    "| 27     | una         |\n",
    "| 30     | mas_de_una  |\n",
    "\n",
    "---\n",
    "\n",
    "#### Corte: `precio ≤ 25.5`\n",
    "\n",
    "- Grupo 1: [18, 21, 24]  \n",
    "  - Clases: nada, mas_de_una, nada  \n",
    "  - $ p_{nada} = 2/3,\\ p_{mas} = 1/3 $  \n",
    "  - Entropía ≈ 0.918\n",
    "\n",
    "- Grupo 2: [27, 30]  \n",
    "  - Clases: una, mas_de_una  \n",
    "  - $ p_{una} = 0.5,\\ p_{mas} = 0.5 $  \n",
    "  - Entropía = 1.0\n",
    "\n",
    "**Entropía total:**\n",
    "\n",
    "$$\n",
    "\\text{Entropía total} = \\frac{3}{5} \\cdot 0.918 + \\frac{2}{5} \\cdot 1.0 = 0.951\n",
    "$$\n",
    "\n",
    "> Si otro corte genera una entropía total menor, será preferido por el árbol.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones del ejemplo aplicado a `ventas_cat`\n",
    "\n",
    "1. **El árbol de clasificación evalúa cortes para reducir la mezcla entre clases.**\n",
    "   - En este caso, se busca dividir la variable `precio` para lograr nodos más homogéneos respecto de `ventas_cat` (nada, una, más_de_una).\n",
    "\n",
    "2. **El corte `precio ≤ 25.5` genera grupos con entropías moderadamente altas.**\n",
    "   - El Grupo 1 tiene dos clases: `nada` (66%) y `mas_de_una` (33%) → Entropía ≈ 0.918\n",
    "   - El Grupo 2 tiene `una` (50%) y `mas_de_una` (50%) → Entropía = 1.0\n",
    "   - Aunque el Grupo 1 tiene una mayoría clara, el Grupo 2 está perfectamente mezclado entre dos clases, lo que incrementa la incertidumbre.\n",
    "   - **La entropía total ponderada del corte (≈ 0.951) representa la impureza residual.**\n",
    "   - Resume cuán \"mixtas\" quedaron las clases después del split. Es el criterio que el árbol usa para decidir si ese punto de corte es bueno.\n",
    "\n",
    "3. **El árbol buscará un corte con menor entropía total si lo hay.**\n",
    "   - Si otro umbral de `precio` produce una división donde uno o ambos grupos son más homogéneos (con menos entropía), se preferirá ese.\n",
    "\n",
    "4. **El corte no predice aún una clase, pero prepara el camino para decidirla.**\n",
    "\n",
    "Cuando se aplica un corte (por ejemplo, `precio ≤ 25.5`), el árbol no está prediciendo directamente una clase. Lo que hace en ese momento es dividir el conjunto de datos en dos grupos distintos, según los valores de esa variable.\n",
    "\n",
    "Cada grupo resultante contiene casos que pertenecen a distintas clases, y el objetivo es que uno de esos grupos sea más \"puro\" (es decir, que tenga una clase mayoritaria clara).\n",
    "\n",
    "Luego del corte:\n",
    "\n",
    "- En cada grupo, el árbol evalúa la distribución de clases.\n",
    "- Si una clase aparece con más frecuencia que las demás, se considera la **clase mayoritaria** y se utiliza como predicción en ese nodo hoja.\n",
    "- El **corte define los subconjuntos** en los que se tomará una decisión.\n",
    "- La **predicción de clase** se hace una vez que ya no se puede (o no conviene) dividir más.\n",
    "\n",
    "5. **Este proceso se repite recursivamente en cada rama del árbol.**\n",
    "   - Luego del primer split (`precio ≤ 25.5`), cada grupo puede ser subdividido nuevamente usando otra variable que reduzca la entropía local.\n",
    "   - Así se construye la jerarquía de reglas que forma el árbol completo.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparación con árboles de regresión\n",
    "\n",
    "- En regresión se mide el **error cuadrático medio** (MSE), que representa la dispersión respecto a un valor promedio:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "- En clasificación, se mide la **impureza** del nodo, por ejemplo con `entropía`, que mide la mezcla de clases.\n",
    "\n",
    "- Ambos enfoques buscan el mismo objetivo: nodos lo más homogéneos posible según la variable objetivo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ¿Cómo se predice una clase en un Árbol de Clasificación?\n",
    "\n",
    "Una vez que el árbol ha dividido los datos mediante cortes sucesivos, cada ruta termina en un **nodo hoja**. Allí es donde se asigna finalmente una **predicción de clase**. Este proceso se basa en los siguientes pasos:\n",
    "\n",
    "Cada vez que el árbol evalúa una variable (por ejemplo, precio ≤ 25.5), divide el conjunto de datos en dos ramas: una a la izquierda (cumple la condición) y otra a la derecha (no la cumple). Al seguir una decisión tras otra —cada una con su condición— se va recorriendo una ruta única.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "- Si `paginas_visitadas ≤ 5.5`  \n",
    "- Y `logueado == 0`  \n",
    "- Y `rating_promedio ≤ 3.2`  \n",
    "→ entonces se predice: clase `'nada'`\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Cada caso del dataset atraviesa el árbol\n",
    "\n",
    "En cada nivel del árbol, se aplica una condición (por ejemplo: `precio ≤ 25.5`).  \n",
    "Si el caso cumple la condición, va por la **rama izquierda**. Si no, va por la **rama derecha**.  \n",
    "Esto se repite con otras variables y umbrales, hasta que el caso cae en un nodo final.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. El nodo hoja (leaf)\n",
    "\n",
    "Todos los casos que siguen la misma secuencia de decisiones terminan en un mismo nodo hoja.\n",
    "\n",
    "Estos puntos de corte fueron seleccionados por ser los que minimizan entropía.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. En la hoja, se cuenta cuántos casos hay de cada clase\n",
    "\n",
    "Una vez que el árbol ha clasificado los datos del entrenamiento, cada nodo hoja contiene un subconjunto de observaciones. Se contabilizan cuántas observaciones corresponden a cada clase:\n",
    "\n",
    "| Clase         | Frecuencia |\n",
    "|---------------|------------|\n",
    "| `nada`        | 3          |\n",
    "| `una`         | 1          |\n",
    "| `mas_de_una`  | 6          |\n",
    "\n",
    "Estas frecuencias se obtienen contando cuántos casos del entrenamiento que llegaron a ese nodo pertenecen a cada clase.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. El árbol predice la clase más frecuente del nodo hoja\n",
    "\n",
    "- En el ejemplo anterior, la clase `mas_de_una` es la más frecuente → esa será la predicción para ese nodo hoja.\n",
    "- Si luego un nuevo dato (no visto) recorre esa misma ruta, el modelo le asignará la misma clase (`mas_de_una`).\n",
    "\n",
    "---\n",
    "\n",
    "### 5. ¿Qué pasa si el nodo está muy mezclado?\n",
    "\n",
    "Si el nodo hoja contiene varias clases en proporciones similares (por ejemplo: 4 casos de `una`, 3 de `nada`, 3 de `mas_de_una`):\n",
    "\n",
    "- La entropía será alta, indicando mayor incertidumbre.\n",
    "- El árbol de todas formas asignará la clase más frecuente (aunque la diferencia sea mínima).\n",
    "- Esa predicción será menos confiable, ya que la clase mayoritaria tiene poca ventaja frente a las otras.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. La entropía no predice, pero anticipa la incertidumbre\n",
    "\n",
    "La entropía no da una clase como salida, pero indica:\n",
    "\n",
    "- Cuánto podemos confiar en la predicción de ese nodo (o combinaciones de cortes, que llevan a ese nodo).\n",
    "- Si la entropía es alta, hay mezcla de clases → la predicción tendrá más margen de error.\n",
    "- Si es baja (cercana a 0), la predicción será confiable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de tree de clasificación con entropía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mis_funciones.view_dectree import view_dectree\n",
    "from mis_funciones.view_detail_text_cattree import view_text_cattree_detailed, view_text_cattree_pruned\n",
    "\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "# Clasificación de variable target\n",
    "\n",
    "# Separamos la variable ventas_cat en tres valores: NADA, UNA y MÁS DE UNA\n",
    "\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "# Usamos -1 como límite inferior para asegurar que 0 quede en la categoría 'nada'\n",
    "# Esto es porque el método pd.cut() excluye el límite superior, por lo que 0 quedaría sin categoría:  pd.cut cierra el límite izquierdo y abre el derecho: (a, b]\n",
    "# Si usáramos [0,1,2] los valores = 0 quedarían excluidos del primer bin\n",
    "# Con [-1,0,1] capturamos:\n",
    "#   - 'nada': ventas = 0\n",
    "#   - 'una': ventas = 1  \n",
    "#   - 'mas_de_una': ventas > 1\n",
    "\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "\n",
    "y = df['ventas_cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento del árbol con entropía\n",
    "clf = DecisionTreeClassifier(max_depth=4, criterion='entropy', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# visualización del Árbol en texto plano, sin detalles \n",
    "tree_text = export_text(clf, feature_names=list(X.columns))\n",
    "print(\"\\n=== ÁRBOL DE CLASIFICACIÓN (salida básica default) ===\\n\")\n",
    "print(tree_text)\n",
    "\n",
    "# Visualización simple del árbol\n",
    "plt.figure(figsize=(12, 8)) \n",
    "tree.plot_tree(clf, filled=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Visualización avanzada de árbol, función propia, ver mis_funciones.py | detallada y editable---\n",
    "view_dectree(\n",
    "    tree_model=clf,\n",
    "    features=list(X.columns),\n",
    "    nombre_base='arbol_clasificacion_ventas',\n",
    "    horizontal_spacing=1.0,\n",
    "    vertical_spacing=1.2,\n",
    "    font_size=16,\n",
    "    flecha_grosor_factor=2,\n",
    "    min_leaf_pct=0.01\n",
    ")\n",
    "\n",
    "print(\"\\n=== Árbol categórico con métricas ===\\n\")\n",
    "print(view_text_cattree_detailed(clf, X.columns))\n",
    "\n",
    "print(\"\\n=== Árbol categórico con poda visual (hojas <0.5% ocultas) ===\\n\")\n",
    "print(view_text_cattree_pruned(clf, X.columns, min_pct=0.5))\n",
    "\n",
    "# Evaluación -  indicadores básicos para el modelo de clasificación\n",
    "print(\"\\n=== EVALUACIÓN DEL MODELO DE CLASIFICACIÓN ===\\n\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_test_str = y_test.astype(str)\n",
    "y_pred_str = pd.Series(y_pred).astype(str)\n",
    "acc = accuracy_score(y_test_str, y_pred_str)\n",
    "prec = precision_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "rec = recall_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision (weighted): {prec:.4f}\")\n",
    "print(f\"Recall (weighted): {rec:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas básicas para evaluar árboles de decisión categóricos\n",
    "\n",
    "Cuando el árbol de decisión clasifica una variable categórica (como `ventas_cat`), las métricas cambian respecto al caso de regresión. En lugar de calcular cuánto se aleja una predicción de un valor continuo (como en MSE), se evalúa si la clase predicha coincide o no con la real, y cómo se distribuyen los errores entre las distintas clases. Las principales métricas son:\n",
    "\n",
    "---\n",
    "\n",
    "#### `Accuracy`\n",
    "- **Qué mide:** proporción de predicciones correctas sobre el total.\n",
    "- **Fórmula:** `accuracy = (TP + TN) / Total` (solo válida en binaria; en multiclase se generaliza como aciertos totales / total casos).\n",
    "- **Interpretación:** indica qué porcentaje del total fue correctamente clasificado.\n",
    "- **Lectura típica:** `Accuracy (exactitud): 0.4070` → el 40.70% de las observaciones fueron correctamente clasificadas.\n",
    "\n",
    "- **`TP (True Positives)`**: cantidad de casos que el modelo predijo como positivos y que realmente eran positivos.  \n",
    "  Ejemplo: el modelo predice \"compra\" y efectivamente el usuario compró.\n",
    "\n",
    "- **`TN (True Negatives)`**: cantidad de casos que el modelo predijo como negativos y que realmente eran negativos.  \n",
    "  Ejemplo: el modelo predice \"no compra\" y efectivamente el usuario no compró.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Estas categorías son claras en un problema binario (dos clases). En problemas multiclase, se generalizan evaluando clase por clase como si fuera binaria (uno contra el resto), y luego se agregan los resultados.\n",
    "\n",
    "---\n",
    "\n",
    "#### `Precision` (ponderada)\n",
    "- **Qué mide:** de todos los casos que el modelo etiquetó como pertenecientes a una clase, cuántos realmente lo eran.\n",
    "- **Fórmula por clase:** `precision = TP / (TP + FP)`\n",
    "\n",
    "- **`FP (False Positives)`**: cantidad de casos que el modelo predijo como positivos pero que realmente eran negativos.  \n",
    "  Ejemplo: el modelo predice \"compra\" pero el usuario no compró.\n",
    "- **En promedio ponderado:** cada clase contribuye en proporción a su tamaño.\n",
    "- **Interpretación:** muestra cuántas predicciones correctas hizo el modelo entre todos los positivos que predijo. Alta precisión = pocas falsas alarmas.\n",
    "- **Lectura típica:** `Precision (ponderada): 0.2883` → muchas predicciones no coincidieron con su clase real; baja fiabilidad por categoría.\n",
    "\n",
    "---\n",
    "\n",
    "#### `Recall` (sensibilidad, ponderado)\n",
    "- **Qué mide:** de todos los casos reales de una clase, cuántos fueron correctamente predichos.\n",
    "- **Fórmula por clase:** `recall = TP / (TP + FN)`\n",
    "- **`FN (False Negatives)`**: cantidad de casos que el modelo predijo como negativos pero que realmente eran positivos.  \n",
    "  Ejemplo: el modelo predice \"no compra\" pero el usuario compró.\n",
    "- **En promedio ponderado:** pondera por soporte (cantidad de verdaderos casos).\n",
    "- **Interpretación:** indica cuántos positivos reales fueron detectados. Bajo recall = el modelo \"no ve\" muchas ocurrencias reales.\n",
    "- **Lectura típica:** `Recall (ponderado): 0.4070` → el modelo reconoce el 40.70% de los verdaderos casos de cada clase.\n",
    "\n",
    "#### `F1 Score` (ponderado)\n",
    "- **Qué mide:** equilibrio entre precisión y recall. Castiga tanto los falsos positivos como los falsos negativos.\n",
    "- **Fórmula:** `F1 = 2 * (precision * recall) / (precision + recall)`\n",
    "- **Interpretación:** útil cuando queremos asegurar que ni la precisión ni el recall son bajos. \n",
    "- **Lectura típica:** `F1 Score (ponderado): 0.3244` → el modelo no logra balancear bien aciertos vs. errores.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "### Diferencias con Regresion Tree\n",
    "- En regresión se evalúan desviaciones (`MSE`, `RMSE`, etc.) de una variable continua. No hay clases ni categorías.\n",
    "- En clasificación, se mide qué tan bien se distingue entre clases discretas, sin importar la magnitud del error numérico.\n",
    "- Las métricas de clasificación permiten identificar sesgos estructurales (por ejemplo, no detectar nunca una clase).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación estructural entre Árbol de Regresión (MSE) y Árbol Categórico (Entropía)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Tabla de Comparación de Árboles</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            color: #000000;\n",
    "            background-color: #f8f9fa;\n",
    "            margin: 0;\n",
    "            padding: 20px;\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "        }\n",
    "        .table-container {\n",
    "            width: 900px;\n",
    "            overflow-x: auto;\n",
    "            background-color: #ffffff;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "            padding: 15px;\n",
    "        }\n",
    "        table {\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            font-size: 0.9em;\n",
    "        }\n",
    "        caption {\n",
    "            font-size: 1.5em;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 15px;\n",
    "            color: #000000;\n",
    "            text-align: left;\n",
    "        }\n",
    "        th, td {\n",
    "            border: 1px solid #dee2e6;\n",
    "            padding: 12px 15px;\n",
    "            text-align: left;\n",
    "            vertical-align: top;\n",
    "        }\n",
    "        thead th {\n",
    "            background-color: #007bff;\n",
    "            color: #000000;\n",
    "            font-weight: bold;\n",
    "            position: sticky;\n",
    "            top: 0;\n",
    "            z-index: 1;\n",
    "        }\n",
    "        tbody tr:nth-child(even) {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "        tbody tr:hover {\n",
    "            background-color: #e9ecef;\n",
    "            cursor: default;\n",
    "        }\n",
    "        td:first-child {\n",
    "            font-weight: 500;\n",
    "            color: #000000;\n",
    "        }\n",
    "        td {\n",
    "            line-height: 1.5;\n",
    "            color: #000000;\n",
    "        }\n",
    "        td code {\n",
    "            background-color: #e8e8e8;\n",
    "            padding: 2px 4px;\n",
    "            border-radius: 3px;\n",
    "            font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;\n",
    "            color: #000000;\n",
    "        }\n",
    "        /* Nuevo estilo para separar las columnas */\n",
    "        th:nth-child(4), td:nth-child(4) {\n",
    "            border-left: 3px solid #007bff;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<div class=\"table-container\">\n",
    "    <table>\n",
    "        <caption>Comparativa de Modelos de Árboles de Decisión</caption>\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th>Variable</th>\n",
    "                <th>Árbol de Regresión (MSE)</th>\n",
    "                <th>Interacción estructural en árbol (MSE)</th>\n",
    "                <th>Árbol Categórico (Entropía)</th>\n",
    "                <th>Interacción estructural en árbol (Entropía)</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>Clicks</td>\n",
    "                <td>Condición Intermedia (nivel 3)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 0, rating ≤ 2.53</td>\n",
    "                <td>Condición Intermedia (nivel 3)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 0, rating ≤ 3.84</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Tiempo_Browsing</td>\n",
    "                <td>Condición Intermedia (nivel 3)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 0, rating ≤ 2.53</td>\n",
    "                <td>Criterio Final de Decisión (nivel 4)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 0, rating ≤ 3.84</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Paginas_Visitadas</td>\n",
    "                <td>Variable de Segmentación Raíz (nivel 0)</td>\n",
    "                <td>estructura todas las ramas</td>\n",
    "                <td>Variable de Segmentación Raíz (nivel 0)</td>\n",
    "                <td>estructura todas las ramas</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Domingo</td>\n",
    "                <td>Condición Intermedia (nivel 2)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 1</td>\n",
    "                <td>Condición Intermedia (nivel 3)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 1</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Dia_Semana</td>\n",
    "                <td>Condición Intermedia (nivel 2)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 1</td>\n",
    "                <td>-</td>\n",
    "                <td>-</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Hora</td>\n",
    "                <td>Criterio Final de Decisión (nivel 4)</td>\n",
    "                <td>cuando paginas_visitadas > 9.5, precio > 19.28</td>\n",
    "                <td>-</td>\n",
    "                <td>-</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Logueado</td>\n",
    "                <td>Condición Estructurante (nivel 1)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5 y también en ramas > 5.5</td>\n",
    "                <td>Condición Intermedia (nivel 2–3)</td>\n",
    "                <td>en ambas ramas, diferencia uso de descuento y rating</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Codigo_Promocional</td>\n",
    "                <td>Criterio Final de Decisión (nivel 4)</td>\n",
    "                <td>cuando paginas_visitadas > 5.5, logueado == 1</td>\n",
    "                <td>Condición Intermedia (nivel 2)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Precio</td>\n",
    "                <td>Condición Intermedia (niveles 2–3)</td>\n",
    "                <td>cuando rating > 2.53 o logueado == 1</td>\n",
    "                <td>Condición Intermedia (nivel 3)</td>\n",
    "                <td>en ramas anónimas con rating alto o fin de semana</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Descuento</td>\n",
    "                <td>Condición Intermedia (niveles 2–3)</td>\n",
    "                <td>cuando paginas_visitadas > 5.5, logueado == 1</td>\n",
    "                <td>Condición Intermedia (nivel 3–4)</td>\n",
    "                <td>en ramas de páginas altas, afecta especialmente edad > 25</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Rating</td>\n",
    "                <td>Condición Estructurante (nivel 1)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 5.5, logueado == 0</td>\n",
    "                <td>Condición Intermedia (nivel 2–3)</td>\n",
    "                <td>en ambas ramas, activa criterio sobre precio o edad</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Edad</td>\n",
    "                <td>Criterio Final de Decisión (nivel 4)</td>\n",
    "                <td>cuando paginas_visitadas ≤ 9.5, logueado == 0</td>\n",
    "                <td>Criterio Final de Decisión (nivel 4)</td>\n",
    "                <td>cuando paginas_visitadas > 9.5</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Codigo_Promocional</td>\n",
    "                <td>Criterio Final de Decisión (nivel 4)</td>\n",
    "                <td>cuando paginas_visitadas > 5.5, logueado == 1</td>\n",
    "                <td>Condición Intermedia (nivel 2)</td>\n",
    "                <td>diferencia ramas entre usuarios anónimos o no, fin de semana</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Es_Domingo</td>\n",
    "                <td>-</td>\n",
    "                <td>-</td>\n",
    "                <td>Condición Intermedia (nivel 3)</td>\n",
    "                <td>bajo ramas con código promocional</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cómo comparar y qué implican las diferencias entre un Árbol de Regresión (MSE) y un Árbol Categórico (Entropía)\n",
    "\n",
    "\n",
    "La tabla permite analizar **qué variables usa cada árbol, en qué niveles de decisión**, y **en qué condiciones contextuales**. La comparación es útil porque los modelos responden a objetivos distintos:\n",
    "\n",
    "| Criterio de división | Árbol de Regresión           | Árbol Categórico              |\n",
    "|----------------------|------------------------------|-------------------------------|\n",
    "| Qué optimiza         | Reducción del **error cuadrático medio** MSE | Reducción de la **entropía de clase**  (mejora pureza)     |\n",
    "| Qué busca            | Mejorar la **predicción del valor continuo** (CUÁNTAS ventas) | Mejorar la **clasificación correcta** (predecir categorías de venta) -> [0, 1, +1] |\n",
    "| Por qué varía la estructura | Algunas variables explican mejor la **magnitud**, pero no discriminan bien clases | Algunas variables separan bien clases, aunque no mejoran la predicción continua |\n",
    "| Ejemplo | `\"hora\" explica cuánto más se vende, cuando se vende`  | `\"hora\" no diferencia, no aparece en el árbol (su variación entra dentro de +1 en categorical)` |\n",
    "\n",
    "#### Claves para comparar ramas y condiciones\n",
    "\n",
    "- **Variables comunes en ambos árboles**: indican robustez —aportan tanto para clasificar como para predecir valores.\n",
    "- **Variables exclusivas de un árbol**: indican especificidad —responden a un objetivo y no al otro.\n",
    "- **Nivel de profundidad**: cuanto más arriba aparece una variable (menor nivel), más estructural es en ese árbol.\n",
    "- **Contexto de uso**: se deben observar las condiciones bajo las cuales una variable entra en juego.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión práctica\n",
    "\n",
    "Si pueden, usen ambas aproximaciones. :) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Variables diferenciadas y recomendaciones de acción  \n",
    "_Comparación entre Árbol de Regresión (MSE) y Árbol Categórico (Entropía)_\n",
    "\n",
    "---\n",
    "\n",
    "### 1. `Codigo_Promocional`\n",
    "\n",
    "**Análisis comparado:**\n",
    "- Aparece en **ambos modelos**, pero con **jerarquía distinta**:\n",
    "  - **Regresión**: es un **criterio final**, de peso marginal.\n",
    "  - **Clasificación**: es una **condición intermedia**, usada para segmentar grupos de usuarios.\n",
    "- Esto sugiere que **su efecto es moderado para predecir el total**, pero **relevante para diferenciar clases**.\n",
    "\n",
    "**Qué recomendar:**\n",
    "- Activar `codigo_promocional` **solo para usuarios con navegación baja** (≤ 5.5 páginas).\n",
    "- **Mostrar códigos de descuento visibles desde el inicio**, ya que el árbol categórico los identifica como impulsores de compra múltiple en ese segmento.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `Es_Domingo`\n",
    "\n",
    "**Análisis comparado:**\n",
    "- Aparece **solo en el árbol de clasificación**.\n",
    "- No incide sobre el volumen de ventas total, pero **segmenta bien ciertos patrones de comportamiento** (p. ej. usuarios más proclives a comprar más de un ítem).\n",
    "\n",
    "**Qué recomendar:**\n",
    "- Usar `es_domingo` como **disparador simplificado de promociones**.\n",
    "- En días domingo, **reducir personalización** y aplicar **campañas planas**, ya que otros factores pierden peso predictivo.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `Rating`, `Descuento` y `Tiempo_Browsing`\n",
    "\n",
    "**Análisis comparado:**\n",
    "- Están **presentes en ambos árboles**, pero con **niveles y funciones diferentes**.\n",
    "  - `Rating` y `Descuento` tienen **efectos cruzados** sobre valor y clases.\n",
    "  - `Tiempo_Browsing` aparece como **criterio final solo en clasificación**.\n",
    "- Esto indica que su influencia **varía según el objetivo** (valor continuo vs. clase).\n",
    "\n",
    "**Qué recomendar:**\n",
    "- **Rating alto (> 3.84)**: aplicar **descuentos automáticos**, incluso sin login o historial profundo. El modelo muestra que sustituye otras señales.\n",
    "- **Tiempo de navegación alto** con bajo rating: **reforzar estímulos** (ej. ventanas emergentes, CTA) aunque otros indicadores sean débiles.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. `Edad`\n",
    "\n",
    "**Análisis comparado:**\n",
    "- Presente en ambos modelos, pero en diferentes contextos:\n",
    "  - En regresión, como **criterio final puntual**.\n",
    "  - En clasificación, **solo en usuarios con navegación alta** (> 9.5 páginas).\n",
    "- Su impacto se restringe a **casos con fuerte involucramiento**.\n",
    "\n",
    "**Qué recomendar:**\n",
    "- En jóvenes con navegación alta y buen rating, usar **promociones cruzadas** o **bundles** para empujar la compra múltiple.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. `Dia_Semana` y `Hora`\n",
    "\n",
    "**Análisis comparado:**\n",
    "- Aparecen **solo en el árbol de regresión**.\n",
    "- Señalan **momentos del día o semana con mayor volumen de ventas**, pero **no aportan segmentación conductual clara**.\n",
    "\n",
    "**Qué recomendar:**\n",
    "- Usar estas variables para **planificar campañas horarias o semanales**, no para personalizar contenidos.\n",
    "- Ejemplo: más ventas los viernes a la tarde → reforzar campañas de remarketing en ese slot.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Overfitting\n",
    "\n",
    "\n",
    "### ¿Qué es el overfitting en árboles de clasificación categórica?\n",
    "\n",
    "---\n",
    "\n",
    "## Explicación paso a paso\n",
    "\n",
    "- **Overfitting** significa que el modelo \"aprendió demasiado\" los datos de entrenamiento.\n",
    "- No aprendió los patrones generales, sino **detalles específicos** que no se repiten en datos nuevos.\n",
    "- En vez de generalizar, **memoriza**: si ve el mismo dato, responde bien; si cambia un poco, falla.\n",
    "\n",
    "### Ejemplo simple\n",
    "Un árbol que clasifica usuarios según edad y clicks, y crea reglas como:\n",
    "- \"Si edad = 36 y clicks = 4, entonces clase = 'una'\"\n",
    "Eso funciona si alguien tiene justo esa combinación, pero no para casos nuevos.\n",
    "\n",
    "\n",
    "\n",
    "- Accuracy: 0.4070\n",
    "- Precision (weighted): 0.2883\n",
    "- Recall (weighted): 0.4070\n",
    "- F1 Score (weighted): 0.3244\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo se manifiesta en árboles categóricos?\n",
    "\n",
    "- **Profundidad excesiva**: muchas divisiones que capturan ruido.\n",
    "- **Hojas muy pequeñas**: el modelo llega a reglas con muy pocos casos (1 o 2).\n",
    "- **Clase minoritaria sobreajustada**: inventa reglas raras para detectar los pocos casos de una clase poco frecuente.\n",
    "\n",
    "---\n",
    "\n",
    "## Señales de overfitting\n",
    "\n",
    "- `Accuracy` en test más `baja` que en entrenamiento.\n",
    "- `F1 score` `alto` sólo en clases frecuentes.\n",
    "- `Recall` muy `bajo` en clases pequeñas.\n",
    "- Árbol muy complejo con muchas ramas que no aportan mejora clara.\n",
    "- `n BAJO GENERALIZADO en clases leaf (o hoja, o final del árbol)`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "# Crear variable categórica target\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "# Variables predictoras\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_cat']\n",
    "\n",
    "# División en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo clasificación profundidad  = 4 --> a esta profundidad la definimos discresional y arbitrariamente. \n",
    "# Elegimos 4 porque en el regresion tree tenía sentido esa profundidad. Probemos acá a ver si da bien. \n",
    "clf = DecisionTreeClassifier(max_depth=4, criterion='entropy', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n=== Evaluación del Modelo de Clasificación (profundidad 4) ===\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n--- Support por clase (n de cada categoría en test set) ---\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo de Clasificación (Decision Tree - Profundidad 4)\n",
    "#### Métricas generales\n",
    "\n",
    "| Métrica     | Valor   |\n",
    "|-------------|---------|\n",
    "| Accuracy    | 0.4070  |\n",
    "| Precision   | 0.2883  |\n",
    "| Recall      | 0.4070  |\n",
    "| F1 Score    | 0.3244  |\n",
    "\n",
    "- **Accuracy** indica que el modelo acierta en la clasificación (predicción) del 40.7% de los casos (todo el sample).\n",
    "- **Precision baja**: muchas predicciones son incorrectas, especialmente para clases minoritarias (dentro de la clase relativa, no todo el sample).\n",
    "- **Recall moderado**: el modelo identifica correctamente el 40.7% de los casos positivos reales (contrafactual real vs predicho - aciertos y e y_hat).\n",
    "- **F1 Score** intermedio: refleja un equilibrio pobre entre precision y recall (es el promedio armónico $2*(recall*precision)/(recall+precision)$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploremos en detalle:  Diferencia entre Precision y Recall \n",
    "\n",
    "Ambas métricas evalúan el desempeño del modelo **por clase específica**, pero desde ángulos distintos: uno enfocado en lo que el modelo predice (precision), y otro en lo que realmente ocurre (recall).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Precision**\n",
    "\n",
    "- **Qué mide:** qué tan precisas son las predicciones de una clase.\n",
    "- **Fórmula:**  \n",
    "  $$\n",
    "  \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "  $$\n",
    "\n",
    "- **Interpretación:**  \n",
    "  De todos los casos que el modelo **predijo como positivos** (por ejemplo: predijo \"compra\"), ¿cuántos **realmente lo eran**?\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Recall**\n",
    "\n",
    "- **Qué mide:** qué tan bien el modelo encuentra los casos reales de una clase.\n",
    "- **Fórmula:**  \n",
    "  $$\n",
    "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "  $$\n",
    "\n",
    "- **Interpretación:**  \n",
    "  De todos los casos que **realmente eran positivos** (por ejemplo: usuarios que compraron), ¿cuántos **fueron detectados** por el modelo?\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Ejemplito claro**\n",
    "\n",
    "Supongamos que estamos analizando la clase `compra`:\n",
    "\n",
    "\n",
    "| Caso | Clase real | Predicción del modelo |\n",
    "|------|------------|------------------------|\n",
    "| 1    | compra     | compra                 |\n",
    "| 2    | compra     | compra                 |\n",
    "| 3    | compra     | no compra              |\n",
    "| 4    | compra     | no compra              |\n",
    "| 5    | compra     | no compra              |\n",
    "| 6    | no compra  | compra                 |\n",
    "| 7    | no compra  | no compra              |\n",
    "| 8    | no compra  | no compra              |\n",
    "\n",
    "**Totales:**\n",
    "- TP = 2 (1, 2)\n",
    "- FN = 3 (3, 4, 5)\n",
    "- FP = 1 (6)\n",
    "- TN = 2 (7, 8)\n",
    "\n",
    "---\n",
    "\n",
    "#### Nuevos cálculos:\n",
    "\n",
    "- `Precision = 2 / (2 + 1) = 0.666`\n",
    "- `Recall = 2 / (2 + 3) = 0.400`\n",
    "- `F1 Score = 2 * (0.666 * 0.4) / (0.666 + 0.4) ≈ 0.5`\n",
    "- `Accuracy = (2 + 2) / 8 = 0.5`\n",
    "\n",
    "---\n",
    "\n",
    "**Interpretación:**\n",
    "- `Precision` mejora: de 3 predicciones de \"compra\", 2 fueron correctas.\n",
    "- `Recall` baja: el modelo detecta sólo 2 de los 5 casos reales de \"compra\".\n",
    "- `F1` refleja este desequilibrio.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Comparación intuitiva\n",
    "\n",
    "| Métrica   | Enfocada en...                           | Pregunta que responde                                  |\n",
    "|-----------|-------------------------------------------|--------------------------------------------------------|\n",
    "| Precision | Predicciones del modelo                   | ¿Cuántas veces acerté cuando **dije que sí**?          |\n",
    "| Recall    | Casos reales de la clase                  | ¿Cuántas veces **dije que sí cuando debía hacerlo**?   |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Volvemos a nuestras métricas reales\n",
    "\n",
    "| Métrica     | Valor   | Qué indica                                                      |\n",
    "|-------------|---------|------------------------------------------------------------------|\n",
    "| Accuracy    | 0.4070  | El 40.7% del total fue correctamente clasificado.               |\n",
    "| Precision   | 0.2883  | Sólo el 28.83% de las predicciones positivas fueron correctas.  |\n",
    "| Recall      | 0.4070  | Se identificó el 40.7% de los positivos reales.                 |\n",
    "| F1 Score    | 0.3244  | Equilibrio bajo entre precisión y recall; desempeño pobre.      |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Desempeño por clase (`Classification Report`)\n",
    "\n",
    "| Clase        | Precision | Recall | F1-score | Support |\n",
    "|--------------|-----------|--------|----------|---------|\n",
    "| mas_de_una   | 0.43      | 0.78   | 0.56     | 843     |\n",
    "| nada         | 0.00      | 0.00   | 0.00     | 509     |\n",
    "| una          | 0.33      | 0.24   | 0.28     | 648     |\n",
    "\n",
    "- El modelo **predice razonablemente bien** la clase `mas_de_una` (F1 = 0.56).\n",
    "- **No clasifica correctamente** ningún caso de `nada` (precision y recall = 0.00).\n",
    "- La clase `una` es predicha con dificultad (F1 = 0.28).\n",
    "\n",
    "---\n",
    "\n",
    "#### Promedios\n",
    "\n",
    "| Tipo de promedio | Precision | Recall | F1-score |\n",
    "|------------------|-----------|--------|----------|\n",
    "| Macro avg        | 0.25      | 0.34   | 0.28     |\n",
    "| Weighted avg     | 0.29      | 0.41   | 0.32     |\n",
    "\n",
    "- **Macro promedio** penaliza la falta de desempeño en `nada` y `una`.\n",
    "- **Promedio ponderado** mejora ligeramente por el buen desempeño en `mas_de_una`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Matriz de Confusión\n",
    "\n",
    "| Real \\ Predicha | mas_de_una | nada | una |\n",
    "|-----------------|-------------|------|-----|\n",
    "| mas_de_una      | 658         | 1    | 184 |\n",
    "| nada            | 373         | 0    | 136 |\n",
    "| una             | 492         | 0    | 156 |\n",
    "\n",
    "- El modelo **predice masivamente como `mas_de_una`**, incluso cuando la clase real es otra.\n",
    "- Para `nada`, **no hay ningún acierto**.\n",
    "- Para `una`, los errores son frecuentes y tienden a ser confundidos con `mas_de_una`.\n",
    "\n",
    "---\n",
    "\n",
    "### Entonces\n",
    "\n",
    "El modelo está sesgado hacia la clase mayoritaria (`mas_de_una`), logrando buena cobertura de esa clase pero **a costa de ignorar por completo `nada`** y clasificando mal `una`. El `accuracy` se mantiene razonable sólo por la desproporción de clases, pero las métricas por clase revelan un desempeño pobre en términos generales.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Support: ¿Importa el tamaño de cada clase?\n",
    "\n",
    "Sí. Para interpretar bien **precision** y **recall**, es clave tener en cuenta **cuántos casos hay en cada clase**. Esto se llama `support`.\n",
    "\n",
    "#### En nuestro conjunto de test:\n",
    "\n",
    "| Clase        | Casos reales (`support`) | % del sample |\n",
    "|--------------|--------------------------|--------------|\n",
    "| mas_de_una   | 843                      | 42.2%        |\n",
    "| una          | 648                      | 32.4%        |\n",
    "| nada         | 509                      | 25.5%        |\n",
    "\n",
    "- La clase `mas_de_una` tiene mayor representación (42% del test set).\n",
    "- La clase `nada` es la más pequeña (25%).\n",
    "\n",
    "Esto **condiciona el aprendizaje del modelo**:  \n",
    "- El modelo tiende a **optimizar su desempeño en las clases más frecuentes**.\n",
    "- En clases con poco `support`, puede fallar más y aun así mantener un buen `accuracy` general.\n",
    "- Por eso **es crucial mirar precision y recall por clase**, no sólo el promedio.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Qué puede pasar?\n",
    "\n",
    "| Clase poco frecuente (bajo support) | Riesgo común                         |\n",
    "|-------------------------------------|--------------------------------------|\n",
    "| `nada`                              | Recall muy bajo; el modelo la ignora |\n",
    "| `una`                               | Precision baja; muchas falsas alarmas|\n",
    "\n",
    "Esto también es una **señal de potencial overfitting o underfitting (inframodelado)**:  \n",
    "- Si el modelo **memoriza casos raros**, cae en overfitting.  \n",
    "- Si **no logra detectar clases pequeñas**, cae en underfitting y queda subajustado.\n",
    "\n",
    "\n",
    "### Pero cómo sabemos si estos porcentajes están bien? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropía y support, medimos la cantidad de información heterogénea que aporta cada clase\n",
    "\n",
    "# Calcular soporte desde y_test\n",
    "support = y_test.value_counts()\n",
    "\n",
    "#  proporciones\n",
    "total = support.sum()\n",
    "proportions = support / total\n",
    "\n",
    "#  entropía de Shannon\n",
    "entropy_support = -np.sum(proportions * np.log2(proportions))\n",
    "\n",
    "print(f\"\\n--- Entropía del soporte observado: {entropy_support:.4f} bits ---\")\n",
    "print(\"Umbrales orientativos:\")\n",
    "print(\"  Entropía < 1.0  → distribución muy desbalanceada\")\n",
    "print(\"  Entropía ≈ 1.5  → balance moderado entre clases\")\n",
    "print(\"  Entropía > 1.5  → distribución altamente balanceada (máximo ≈ log2(N clases))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de la entropía del soporte\n",
    "\n",
    "La entropía calculada es **1.5546 bits**, lo cual está **ligeramente por encima del umbral de 1.5**.\n",
    "\n",
    "Esto indica que:\n",
    "\n",
    "- La distribución entre las tres clases (`nada`, `una`, `mas_de_una`) es **balanceada**.\n",
    "- No hay una dominancia extrema de una clase sobre las otras.\n",
    "- La entropía máxima posible para 3 clases sería `log2(3) ≈ 1.5849`, lo que marca un escenario perfectamente balanceado (33.3% cada clase). Dado que la entropía observada está muy cerca de ese valor, **el soporte está bastante equilibrado**.\n",
    "\n",
    "**Conclusión**:  \n",
    "El modelo no enfrenta un desbalance severo en la variable objetivo. Por lo tanto, si hay problemas de recall o precisión, **no se deben a una distribución desbalanceada de clases**, sino a **otras limitaciones del modelo** (como **profundidad**, ruido o segmentaciones poco efectivas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre overfitting y underfitting\n",
    "\n",
    "---\n",
    "\n",
    "## Tamaño de clase (n) y riesgo de overfitting\n",
    "\n",
    "- El **overfitting se agrava cuando hay clases con pocos casos**.\n",
    "- Si una clase tiene muy pocos ejemplos (`n` bajo o `< 1%` del total), el árbol puede crear **reglas muy específicas que no se replican**.\n",
    "- Esto lleva a:\n",
    "  - **Recall bajo**: el modelo rara vez acierta esa clase.\n",
    "  - **Precision falsa**: acierta en entrenamiento, pero nunca en test.\n",
    "  - **Ramas inútiles**: hojas creadas para explicar 1 o 2 casos.\n",
    "- **Señal crítica**: si una clase tiene `n < 1%-5%` del total y aún así genera ramas profundas, es síntoma fuerte de overfitting.\n",
    "\n",
    "\n",
    "## Underfitting \n",
    "\n",
    "\t•\tUnderfitting = reglas demasiado generales, sin capturar estructura real. Falta depth y precisión. \n",
    "\n",
    "Esto también puede generar recall bajo y mala precisión. Pero con buen support!! \n",
    "\n",
    "- Entonces: **Underfitting** ocurre cuando el modelo aprende **reglas demasiado generales** y no logra capturar **la estructura real de los datos**.\n",
    "- Se manifiesta típicamente por:\n",
    "  - Baja `accuracy` general.\n",
    "  - `Recall` y `precision` bajos para todas las clases.\n",
    "  - Árboles **poco profundos**, con pocas ramas y divisiones.\n",
    "\n",
    "---\n",
    "\n",
    "### Importante: el support es clave\n",
    "\n",
    "- A diferencia del overfitting, **el underfitting puede ocurrir incluso con clases bien distribuidas (alta entropia)**.\n",
    "- Es decir, el modelo **puede tener buen `support`** (entropía alta y clases equilibradas), pero aún así fallar por no aprender suficientemente.\n",
    "- El problema no es la distribución, sino la **falta de complejidad del modelo** (poca profundidad, pocas divisiones).\n",
    "\n",
    "---\n",
    "\n",
    "### En resumen:\n",
    "\n",
    "| Causa               | Resultado típico                    | Support  |\n",
    "|---------------------|-------------------------------------|----------|\n",
    "| Overfitting         | Buen desempeño en train, pobre en test | Malo / desequilibrado |\n",
    "| Underfitting        | Mal desempeño en train y test       | Bueno / balanceado     |\n",
    "\n",
    "> **El `support` ayuda a descartar causas estructurales. Si está bien balanceado, pero el modelo falla, el problema no es la distribución sino la capacidad del árbol.**\n",
    "    \n",
    "    El saldo se resume en el depth y sus dimensiones\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre el depth\n",
    "\n",
    "#### Entonces el depth óptimo resulta clave para que el modelo no haga ni overfitting ni underfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for d in range(1, 51):\n",
    "    clf = DecisionTreeClassifier(max_depth=d, criterion='entropy', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    resultados.append({\n",
    "        'depth': d,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision_weighted': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'recall_weighted': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "depth_optimo = df_resultados.loc[df_resultados['f1_weighted'].idxmax(), 'depth']\n",
    "\n",
    "print(\"\\n=== Métricas por profundidad ===\")\n",
    "print(\"\\n=== Descripción de métricas (promedio ponderado por clase) ===\")\n",
    "print(\"- accuracy: proporción total de aciertos del modelo sobre todos los casos.\")\n",
    "print(\"           → Esperable: cuanto más alto, mejor. Ideal > 0.70\")\n",
    "\n",
    "print(\"- precision_weighted: precisión promedio de las clases, ponderada por su frecuencia.\")\n",
    "print(\"           → Esperable: alto (algo tipo > 0.60), indica cuántas falsas predicciones positivas se detectaron. Interpretación depende de criticidad de la clase\")\n",
    "print(\"           → al subir, baja los falsos positivos (FP)\")\n",
    "\n",
    "print(\"- recall_weighted: recall promedio de las clases, ponderado por su frecuencia.\")\n",
    "print(\"           → Esperable: alto (algo tipo > 0.60-0.70), indica cuántos positivos reales fueron detectados.\")\n",
    "print(\"           → al subir, baja los falsos negativos (FN)\")\n",
    "\n",
    "print(\"- f1_weighted: media armónica entre precision y recall, ponderada por la frecuencia de clase.\")\n",
    "print(\"           → Esperable: valor equilibrado, algo tipo > 0.50-0.60. Penaliza si alguna métrica para una clase(s) es muy baja.\")\n",
    "print(\"           → baja el error de generalización (EGE) si tiene un valor medio\")\n",
    "\n",
    "print(\"--------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "print(df_resultados.round(4).to_string(index=False))\n",
    "print(f\"\\nProfundidad óptima: {depth_optimo}\")\n",
    "# como ejercicio, a estos indicadores, se podrían agregar deltas para ver el trade-off entre depths y los puntos de saturación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del desempeño del modelo de clasificación por profundidad\n",
    "\n",
    "La evaluación del árbol de decisión muestra tres fases bien diferenciadas:\n",
    "\n",
    "1. **Fase trivial (depth 1 a 3)**\n",
    "El modelo predice casi exclusivamente la clase mayoritaria. Esto se refleja en una accuracy elevada pero engañosa (0.4215), mientras que la precision_weighted y el f1_weighted permanecen muy bajos (≈0.25). No hay aprendizaje efectivo.\n",
    "\n",
    "2. **Fase de ganancia marginal (depth 4 a 20)**\n",
    "Entre depth = 4 y depth = 20, el árbol comienza a aprender reglas útiles. La precision y el f1 ponderados mejoran progresivamente. Sin embargo, hay cierta inestabilidad, con aumentos y retrocesos leves que muestran que el modelo todavía oscila entre generalizar y sobreajustar. El f1_weighted se estabiliza alrededor de 0.36 sin un máximo claro hasta ese punto.\n",
    "\n",
    "3. **Fase de máximo desempeño (depth 33)**\n",
    "El modelo alcanza en depth = 33 sus mejores métricas conjuntas (accuracy: 0.3665, precision_weighted: 0.3663, f1_weighted: 0.3664). Sin embargo, ya en los niveles previos (≈28–32) las métricas habían comenzado a converger. Este punto representa el equilibrio máximo entre precisión y profundidad antes de que se manifiesten síntomas de sobreajuste. No se trata de un salto significativo, sino de una meseta breve de desempeño máximo.\n",
    "\n",
    "    Si hay muchas menos instancias de una clase (como “una”, o \"nada\"), el modelo tiene menos datos para aprenderla. El valor moderado de F1 (≈0.35) no refleja necesariamente mal desempeño, sino las limitaciones impuestas por el desbalance  —tal como lo indica el support, donde hay 25.5% de “nada”—. Esta asimetría tiende a penalizar el rendimiento promedio ponderado de las clases minoritarias, y por lo tanto no deja que el f1 tenga mejor desempeño.\n",
    "\n",
    "4. **Overfitting estructural**\n",
    "A partir de depth = 39, todas las métricas permanecen idénticas hasta depth = 50, a pesar de que el árbol continúa creciendo en depth. Esta estabilización artificial indica que las nuevas divisiones no aportan ningún poder predictivo adicional, y que el modelo ya ha agotado la capacidad de generalizar del conjunto de entrenamiento. Es una señal clara de sobreajuste estructural, no visible por caída de métricas, sino por su congelamiento.\n",
    "\n",
    "\n",
    ">    El modelo logra su mejor desempeño global a depth = 33, y no presenta mejoras más allá de ese punto. A partir de allí, se mantiene constante sin caer en sobreajuste medible por estas métricas. Este comportamiento sugiere que:\n",
    "\n",
    "        •\tEl árbol necesita profundidad elevada para captar las interacciones necesarias entre variables en un problema multiclase desbalanceado.\n",
    "        •\tNo hay señales de sobreajuste severo hasta depth = 50.\n",
    "        •\tEl uso de f1_weighted como criterio es crucial para evitar que el modelo simplemente optimice por la clase mayoritaria.\n",
    "\n",
    "\n",
    "# Moraleja: \n",
    "\n",
    "### Un árbol demasiado superficial subrepresenta el fenómeno (underfitting).\n",
    "### \t•\tUn árbol demasiado profundo comienza a memorizar ruido o combinaciones irrelevantes (overfitting).\n",
    "### \t•\tEl punto óptimo suele encontrarse justo antes de que el modelo empiece a degradar sus métricas por complejidad excesiva.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Diferencias entre Regression Trees y Clasifier Trees\n",
    "\n",
    "### Diferencias en la profundidad óptima entre árboles de regresión y clasificación multiclase\n",
    "\n",
    "La profundidad óptima de un árbol de decisión varía según el tipo de tarea y las características del dataset. En general, los árboles de regresión (`DecisionTreeRegressor`) requieren menos profundidad que los árboles de clasificación multiclase (`DecisionTreeClassifier`). A continuación se detallan las razones, incluyendo la interacción con el tamaño muestral (`n`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Árboles de regresión: ¿Por qué menor profundidad? (si recuerdan, el óptimo era 4!)\n",
    "\n",
    "1. **Variable objetivo continua**  \n",
    "   - Las diferencias entre observaciones se capturan desde niveles tempranos.  \n",
    "   - Las divisiones son eficaces rápidamente al reducir la dispersión.  \n",
    "   - No es necesario separar clases distintas, lo que simplifica la estructura.\n",
    "\n",
    "2. **Reducción de la varianza por nodo e intranodo**  \n",
    "   - Cada split minimiza la varianza dentro de los nodos hijos (reduce MSE).  \n",
    "   - La mejora se vuelve marginal tras pocos niveles.  \n",
    "   - Sobreajuste común más allá de 4–6 niveles.\n",
    "\n",
    "3. **Alta cardinalidad en `y`**  \n",
    "   - `y` puede tener miles de valores únicos (montos de ventas).  \n",
    "   - El árbol puede sobreajustar con facilidad al intentar predecir valores exactos.  \n",
    "   - La complejidad aumenta exponencialmente con profundidad.\n",
    "\n",
    "4. **Sensibilidad al tamaño muestral (`n`)**  \n",
    "   - Con `n` reducido, la profundidad elevada genera nodos vacíos o con bajo n.  \n",
    "   - Esto introduce ruido, inestabilidad y deterioro del arbol.\n",
    "   - El tamaño muestral condiciona directamente la profundidad útil y la estabilidad estructural del árbol.\n",
    "\n",
    "\n",
    "#### Clasificación multiclase: ¿Por qué mayor profundidad? (el óptimo de 33 depth!!!!)\n",
    "\n",
    "1. **Separación de clases discretas**  \n",
    "   - Las reglas deben aislar clases distintas que pueden estar solapadas.  \n",
    "   - Requiere secuencias de condiciones más específicas.  \n",
    "   - La estructura crece hasta que cada clase queda bien delimitada.\n",
    "\n",
    "2. **Presencia de clases minoritarias (desbalance)**  \n",
    "   - Las clases poco frecuentes emergen sólo con suficiente profundidad.  \n",
    "   - El árbol necesita subdividir nodos mayoritarios para llegar a estas clases.  \n",
    "   - La baja profundidad invisibiliza estas estructuras.\n",
    "\n",
    "3. **Optimización del F1 ponderado**  \n",
    "   - Esta métrica valora tanto la precisión como el recall, ponderados por frecuencia.  \n",
    "   - Mejorar el recall en clases pequeñas suele exigir mayor complejidad.  \n",
    "   - La profundidad permite lograr un mejor equilibrio entre cobertura y especificidad.\n",
    "\n",
    "4. **Relación con el tamaño muestral (`n`)**  \n",
    "   - Con `n` elevado, el árbol puede profundizar sin perder estabilidad.  \n",
    "   - Las particiones profundas mantienen suficiente soporte estadístico por nodo.  \n",
    "   - La penalización por complejidad es más lenta cuando `n` es grande.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculamos con depth optimo antes de pasar a ensambling... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                            labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "\n",
    "y = df['ventas_cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=33,\n",
    "    criterion='entropy',\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "tree_text = export_text(clf, feature_names=list(X.columns))\n",
    "\n",
    "view_dectree(\n",
    "    tree_model=clf,\n",
    "    features=list(X.columns),\n",
    "    nombre_base='arbol_clasificacion_ventas',\n",
    "    horizontal_spacing=1.0,\n",
    "    vertical_spacing=1.2,\n",
    "    font_size=16,\n",
    "    flecha_grosor_factor=2,\n",
    "    min_leaf_pct=0.01\n",
    ")\n",
    "\n",
    "print(\"\\n=== Árbol categórico con métricas ===\\n\")\n",
    "print(view_text_cattree_detailed(clf, X.columns))\n",
    "\n",
    "print(\"\\n=== EVALUACIÓN DEL MODELO DE CLASIFICACIÓN ===\\n\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_test_str = y_test.astype(str)\n",
    "y_pred_str = pd.Series(y_pred).astype(str)\n",
    "\n",
    "acc = accuracy_score(y_test_str, y_pred_str)\n",
    "prec = precision_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "rec = recall_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision (weighted): {prec:.4f}\")\n",
    "print(f\"Recall (weighted): {rec:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "\n",
    "print(\"\\n=== DISTRIBUCIÓN DE CLASES ===\\n\")\n",
    "print(\"\\nClases predichas:\")\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "print(\"Atención!:\")\n",
    "\n",
    "print(\"Profundidad real del árbol:\", clf.get_depth())\n",
    "print(\"Cantidad de hojas:\", clf.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si bien encontramos el depth en donde la ganancia no llega, el problema que nos vamos a enfrentar es que la legibilidad del árbol se ve severamente comprometida! \n",
    "\n",
    "#### Apliquemos técnicas de pre-prunning, para limpiar el árbol. \n",
    "\n",
    "#### Esto va a implicar una salida más limpia y una contención mayor de los niveles. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "\n",
    "y = df['ventas_cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento del árbol con pre-pruning\n",
    "# --- AJUSTE NUEVO: min_samples_leaf y min_samples_split en base al 2% del sample ---\n",
    "min_leaf = int(len(X_train) * 0.02)  # mínimo 2% del sample por hoja\n",
    "min_split = int(len(X_train) * 0.05)  # mínimo 5% del sample para split\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=33,\n",
    "    criterion='entropy',\n",
    "    min_samples_leaf=min_leaf,        # nuevo: controlo hojas\n",
    "    min_samples_split=min_split,      # nuevo: controlo divisiones en ramas \n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "tree_text = export_text(clf, feature_names=list(X.columns))\n",
    "\n",
    "view_dectree(\n",
    "    tree_model=clf,\n",
    "    features=list(X.columns),\n",
    "    nombre_base='arbol_clasificacion_ventas',\n",
    "    horizontal_spacing=1.0,\n",
    "    vertical_spacing=1.2,\n",
    "    font_size=16,\n",
    "    flecha_grosor_factor=2,\n",
    "    min_leaf_pct=0.01\n",
    ")\n",
    "\n",
    "print(\"\\n=== Árbol categórico con métricas ===\\n\")\n",
    "print(view_text_cattree_detailed(clf, X.columns))\n",
    "\n",
    "# Evaluación\n",
    "print(\"\\n=== EVALUACIÓN DEL MODELO DE CLASIFICACIÓN ===\\n\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_test_str = y_test.astype(str)\n",
    "y_pred_str = pd.Series(y_pred).astype(str)\n",
    "\n",
    "acc = accuracy_score(y_test_str, y_pred_str)\n",
    "prec = precision_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "rec = recall_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_str, y_pred_str, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision (weighted): {prec:.4f}\")\n",
    "print(f\"Recall (weighted): {rec:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Distribución de clases\n",
    "print(\"\\n=== DISTRIBUCIÓN DE CLASES ===\\n\")\n",
    "print(\"\\nClases predichas:\")\n",
    "print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n\\nAtención!:\")\n",
    "\n",
    "print(\"Profundidad real del árbol:\", clf.get_depth())\n",
    "print(\"Cantidad de hojas:\", clf.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- comparativa_arboles_recomendaciones_detalladas_v5.html -->\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Comparativa con Acciones Estratégicas</title>\n",
    "  <style>\n",
    "    body {\n",
    "      font-family: \"Segoe UI\", Tahoma, Geneva, Verdana, sans-serif;\n",
    "      background-color: #f9f9f9;\n",
    "      color: black;\n",
    "      padding: 40px;\n",
    "      max-width: 1080px;\n",
    "      margin: auto;\n",
    "      line-height: 1.6;\n",
    "    }\n",
    "\n",
    "    h1 {\n",
    "      color: #003366;\n",
    "      border-bottom: 3px solid #003366;\n",
    "      padding-bottom: 8px;\n",
    "      margin-bottom: 30px;\n",
    "    }\n",
    "\n",
    "    table {\n",
    "      border-collapse: collapse;\n",
    "      width: 100%;\n",
    "      margin-top: 30px;\n",
    "      font-size: 0.95em;\n",
    "      color: black;\n",
    "    }\n",
    "\n",
    "    th, td {\n",
    "      border: 1px solid #ccc;\n",
    "      padding: 10px 12px;\n",
    "      text-align: left;\n",
    "      vertical-align: top;\n",
    "      background-color: white;\n",
    "      color: black;\n",
    "    }\n",
    "\n",
    "    th {\n",
    "      background-color: #006699;\n",
    "      color: white;\n",
    "      font-weight: bold;\n",
    "    }\n",
    "\n",
    "    caption {\n",
    "      text-align: left;\n",
    "      font-size: 1.4em;\n",
    "      font-weight: bold;\n",
    "      margin-bottom: 10px;\n",
    "      color: #003366;\n",
    "    }\n",
    "\n",
    "    code {\n",
    "      background-color: #e8e8e8;\n",
    "      padding: 2px 5px;\n",
    "      border-radius: 3px;\n",
    "      font-family: monospace;\n",
    "      color: black;\n",
    "    }\n",
    "\n",
    "    .amarillo td {\n",
    "      background-color: #fff8dc;\n",
    "    }\n",
    "\n",
    "    .verde td {\n",
    "      background-color: #e0f2e0;\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h1>Comparativa de árboles y acciones recomendadas</h1>\n",
    "\n",
    "<table>\n",
    "  <caption>Variables, estructura y recomendaciones de acción</caption>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Variable</th>\n",
    "      <th>Árbol Original (depth=4)</th>\n",
    "      <th>Árbol Ajustado (depth=33 (depth 9+preprune))</th>\n",
    "      <th>Recomendación Estratégica</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><code>paginas_visitadas</code></td>\n",
    "      <td>Raíz</td>\n",
    "      <td>Raíz + subramas amplias</td>\n",
    "      <td>Segmentar desde el inicio por intensidad de exploración. Personalizar desde el 2–3er click. Poca navegación → ofrecer CTA directos (e.g., botón de compra destacado).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>codigo_promocional</code></td>\n",
    "      <td>Segundo nodo</td>\n",
    "      <td>Segundo nodo + con interacciones</td>\n",
    "      <td>Activar descuentos condicionados a navegación previa y rating. Evitar mostrar códigos a <u>usuarios fríos</u> (sin navegación ni interacción).</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>rating_promedio</code></td>\n",
    "      <td>Intermedio</td>\n",
    "      <td>Condición clave en múltiples ramas</td>\n",
    "      <td>Usuarios que navegan productos con bajo rating: mostrar prueba social (opiniones, garantías, devoluciones). Rating alto: usar escasez o urgencia (\"últimos disponibles\").</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>logueado</code></td>\n",
    "      <td>Ausente</td>\n",
    "      <td>Condición estructural</td>\n",
    "      <td>Usuarios logueados tienen comportamiento más predecible: mostrar precios completos sin descuentos. Usuarios anónimos: usar prueba social y CTA directos.</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>clicks</code></td>\n",
    "      <td>Ausente</td>\n",
    "      <td>Intermedio</td>\n",
    "      <td>Muchos clicks → perfil comparador → se puede ofrecer precio más alto con buenos argumentos (reputación, garantía). Pocos clicks → usar ofertas urgentes.</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>edad</code></td>\n",
    "      <td>Marginal</td>\n",
    "      <td>Presente en ramas de decisión final</td>\n",
    "      <td>Ofertas adaptadas por rango etario. Jóvenes: promociones y estética visual. Mayores: destacar soporte, claridad y confianza.</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>tiempo_browsing</code></td>\n",
    "      <td>Ausente</td>\n",
    "      <td>Condición específica con <code>precio</code></td>\n",
    "      <td>Usuarios que navegan mucho sin decidir: lanzar pop-up con descuento por tiempo limitado o CTA fuerte (Call To Action: \"Aprovechá antes de que se agote\").</td>\n",
    "    </tr>\n",
    "    <tr class=\"verde\">\n",
    "      <td><code>precio</code></td>\n",
    "      <td>Intermedio</td>\n",
    "      <td>Condición frecuente</td>\n",
    "      <td>\n",
    "        Diseñar precios dinámicos. Si el usuario pasa por muchas condiciones del árbol (rama profunda), es más probable que tolere precios altos si el valor percibido es alto. <br><br>\n",
    "        Detectar usuarios que cumplen ≥4 condiciones sucesivas del árbol (ej. muchas páginas, logueo, buen rating, múltiples clicks, edad alta). <br>\n",
    "        Considerarlos usuarios de alta intención:<br>\n",
    "        – No ofrecer descuentos automáticos<br>\n",
    "        – Usar CTA de escasez o urgencia (\"últimos lugares\", \"comprado hoy por 28 personas\")<br>\n",
    "        – Elevar ligeramente el precio si el rating es alto<br>\n",
    "        – Priorizar para recomendaciones premium o up-selling\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>descuento_pct</code></td>\n",
    "      <td>Secundaria</td>\n",
    "      <td>Condición intermedia</td>\n",
    "      <td>Usar descuentos como incentivo sólo en usuarios fríos o en productos con bajo rating y usuarios jóvenes. Evitar ofrecerlos a quienes ya muestran intención alta.</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>es_domingo</code></td>\n",
    "      <td>Ausente</td>\n",
    "      <td>Condición puntual</td>\n",
    "      <td>Testear campañas especiales de fin de semana. En usuarios anónimos o logueados con promoción, se potencia el efecto.</td>\n",
    "    </tr>\n",
    "    <tr class=\"amarillo\">\n",
    "      <td><code>es_feriado</code></td>\n",
    "      <td>Ausente</td>\n",
    "      <td>Ausente</td>\n",
    "      <td>No se detectan patrones claros. Requiere más datos específicos de días feriados para tomar decisiones.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Ensembling\n",
    "\n",
    "**Objetivo:** mejorar la robustez y precisión de los modelos basados en árboles de decisión.\n",
    "\n",
    "### Estrategias principales:\n",
    "\n",
    "---\n",
    "\n",
    "1. **Vía Modelos o algoritmos**  \n",
    "   - Combinación de algoritmos diferentes (p. ej., árboles de regresión y de clasificación)\n",
    "   - Combinación de especificaciones de algoritmos (p. ej., depth, pruning)\n",
    "\n",
    "---\n",
    "\n",
    "2. **Training Set**  \n",
    "   - Variación del training set, nuevo training set, diferente training set\n",
    "   - Uso de conjuntos de datos distintos  \n",
    "   - Particiones aleatorias del mismo dataset (submuestreo --> repeated subsampling)\n",
    "\n",
    "---\n",
    "\n",
    "3. **Bagging (Bootstrap Aggregating)**  \n",
    "   - Entrena múltiples árboles sobre subconjuntos diferentes de datos\n",
    "     - Se generan múltiples subconjuntos del dataset original mediante *bootstrap* (muestreo con reemplazo)  \n",
    "   - Combina predicciones para reducir la varianza y se combinan los resultados (promedio, votación)\n",
    "   - Ejemplo: Random Forests\n",
    "\n",
    "---\n",
    "\n",
    "4. **Boosting**  \n",
    "   - Técnica secuencial: los modelos se entrenan uno tras otro  \n",
    "   - Cada nuevo modelo se enfoca en evitar o mitigar los errores cometidos por el modelo anterior  \n",
    "   - Se ajusta el peso de las observaciones: mayor peso a los casos mal predichos (Error-driven learning; Sequential correction on Hardness-weighted sampling)\n",
    "   - Al final, se combinan todos los modelos con un sistema de ponderación (en base al learning rate, que puede decrecer) \n",
    "   - Ejemplo: XGBoost (eXtreme Gradient Boosting)  \n",
    "   - Ventaja: reduce el sesgo del modelo base, mejora la precisión en datasets con relaciones complejas o ruido moderado  \n",
    "   - Requiere regularización y control ESTRICTO de sobreajuste debido a su potencia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Subsampling\n",
    "\n",
    "### Finalidad del procedimiento\n",
    "\n",
    "Este procedimiento tiene como objetivo evaluar la estabilidad y consistencia de un árbol de decisión con profundidad previamente optimizada (depth = 16), aplicado sobre distintas particiones aleatorias del dataset. Permite observar cómo varía el rendimiento general del modelo ante pequeños cambios en la muestra de entrenamiento.\n",
    "\n",
    "### Descripción del proceso\n",
    "\n",
    "1. **Identificación del depth óptimo**  \n",
    "   Previo al muestreo repetido, se identificó la profundidad óptima del árbol de decisión ejecutando una validación sobre una única partición del dataset (70% entrenamiento, 30% test).  \n",
    "   Para ello, se evaluó el desempeño de árboles con distintas profundidades (`max_depth` entre 1 y 50), utilizando el F1 ponderado como criterio de optimización.  \n",
    "   La profundidad que maximizó este indicador fue seleccionada como valor óptimo (depth = 16).\n",
    "\n",
    "2. **Submuestreo aleatorio del dataset**  \n",
    "   En cada iteración, se extrae una submuestra aleatoria del 70% del dataset original para ser usada como conjunto de entrenamiento. El 30% restante no se utiliza en esta etapa. Cada submuestreo se genera con una semilla distinta.\n",
    "\n",
    "3. **Entrenamiento con profundidad fija y evaluación sobre el dataset completo**  \n",
    "   Para cada submuestra, se entrena un árbol de decisión (`DecisionTreeClassifier`) con profundidad fija en 16. Luego se evalúa su rendimiento prediciendo sobre el dataset completo (train + test), calculando los siguientes indicadores:\n",
    "\n",
    "   - Precisión ponderada (`precision_weighted`)  \n",
    "   - Recall ponderado (`recall_weighted`)  \n",
    "   - F1 ponderado (`f1_weighted`)  \n",
    "   - Accuracy total (`accuracy`)\n",
    "\n",
    "Este procedimiento permite verificar si el modelo produce resultados consistentes y si su estructura interna es estable frente a distintos subconjuntos del dataset, lo cual es clave antes de considerar esquemas de ensamblado más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                          labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_cat']\n",
    "\n",
    "# División 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "# Loop para Evaluar el árbol con un rango de distintas profundidades (1 a 50)\n",
    "# buscamos el depth que maximiza el f1_weighted\n",
    "resultados = []\n",
    "\n",
    "for d in range(1, 51):\n",
    "    clf = DecisionTreeClassifier(max_depth=d, criterion='entropy', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    resultados.append({\n",
    "        'depth': d,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision_weighted': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'recall_weighted': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "depth_optimo = df_resultados.loc[df_resultados['f1_weighted'].idxmax(), 'depth']\n",
    "\n",
    "print(df_resultados.round(4).to_string(index=False))\n",
    "print(f\"\\nProfundidad óptima: {depth_optimo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_cat']\n",
    "\n",
    "# Evaluación con repeated subsampling \n",
    "resultados_rf = []\n",
    "n_iteraciones = 50\n",
    "random_states = np.random.randint(0, 10000, size=n_iteraciones) # esto es para que cada split 70/30 sea distinto\n",
    "\n",
    "for seed in random_states:\n",
    "    # repite División 70/30, cada vuelta toma observaciones distintas. La división es siempre 70/30\n",
    "    X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X, y, train_size=0.7, random_state=seed)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=16, random_state=seed)\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "    y_pred = model.predict(X_test_sub)\n",
    "\n",
    "    resultados_rf.append({\n",
    "        'seed': seed,\n",
    "        'accuracy': accuracy_score(y_test_sub, y_pred),\n",
    "        'precision_weighted': precision_score(y_test_sub, y_pred, average='weighted', zero_division=0),\n",
    "        'recall_weighted': recall_score(y_test_sub, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_test_sub, y_pred, average='weighted', zero_division=0),\n",
    "        'n_trees': model.n_estimators,\n",
    "        'avg_depth': np.mean([tree.get_depth() for tree in model.estimators_]),\n",
    "        'report': classification_report(y_test_sub, y_pred, zero_division=0)\n",
    "    })\n",
    "\n",
    "df_resultados_rs = pd.DataFrame(resultados_rf)\n",
    "print(\"=== RESULTADOS REPEATED SUBSAMPLE ===\")\n",
    "display(df_resultados_rs.drop(columns='report').round(4))\n",
    "print(\"\\n--- Descripción estadística ---\\n\")\n",
    "display(df_resultados_rs.drop(columns='report').describe().round(4))\n",
    "\n",
    "print(\"\\n=== COMPARACIÓN CON ÁRBOL DE DECISIÓN ===\")\n",
    "print(\"Repeated Subsample:\")\n",
    "print(f\"Accuracy: {df_resultados_rs['accuracy'].mean():.4f}\")\n",
    "print(f\"Precision (weighted): {df_resultados_rs['precision_weighted'].mean():.4f}\")\n",
    "print(f\"Recall (weighted): {df_resultados_rs['recall_weighted'].mean():.4f}\")\n",
    "print(f\"F1 Score (weighted): {df_resultados_rs['f1_weighted'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nÁrbol de Decisión:\")\n",
    "print(f\"Accuracy: {0.4205:.4f}\")\n",
    "print(f\"Precision (weighted): {0.3840:.4f}\")\n",
    "print(f\"Recall (weighted): {0.4205:.4f}\")\n",
    "print(f\"F1 Score (weighted): {0.3518:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué puede observarse del modelo aunque no se visualicen los paths?\n",
    "\n",
    "Aunque los modelos más complejos (como Random Forest o árboles con muchas iteraciones sobre subconjuntos de datos) no ofrecen reglas de decisión explícitas y trazables, permiten evaluar distintos aspectos clave de su rendimiento y utilidad. A continuación se resumen los principales:\n",
    "\n",
    "### 1. Predicciones confiables sobre nuevos casos\n",
    "Incluso sin conocer la lógica exacta detrás de cada decisión, es posible utilizar el modelo para clasificar observaciones futuras con mayor precisión que modelos más simples. Esto es particularmente útil cuando el objetivo es la performance predictiva y no la interpretabilidad.\n",
    "\n",
    "### 2. Importancia de variables\n",
    "El modelo puede proporcionar métricas de importancia para cada variable de entrada, ya sea a través de su contribución a la reducción de impureza o mediante métodos más robustos como la permutación. Esto permite identificar qué atributos influyen más en las decisiones del modelo, aunque no se conozca cómo interactúan entre sí.\n",
    "\n",
    "### 3. Estabilidad del rendimiento (robustez)\n",
    "Mediante técnicas como el submuestreo repetido (*repeated subsampling*), se puede observar cómo varía el rendimiento del modelo ante cambios en la muestra de entrenamiento. Si los resultados se mantienen estables, el modelo se considera robusto y confiable frente a fluctuaciones en los datos.\n",
    "\n",
    "### 4. Indicadores de balance entre clases\n",
    "El análisis de métricas como *precision*, *recall* y *F1-score* permite detectar si el modelo está sesgado hacia clases mayoritarias o si es capaz de capturar con efectividad eventos poco frecuentes. Esto es clave para problemas con clases desbalanceadas o con mayor costo de error en ciertas categorías.\n",
    "\n",
    "En conjunto, estos elementos permiten validar la capacidad del modelo para generalizar, evaluar su confiabilidad estadística y entender parcialmente su comportamiento, incluso en ausencia de una representación visual directa de sus reglas internas.\n",
    "\n",
    "#### Es esperable que en estas técnicas de bagging (como subsampling) encontremos resultados **más robustos** pero menos precisos. Es decir, los indicadores se deterioran debido a que intruducimos \"ruido\" aleatorio en cada selección de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "                          +--------------------+\n",
    "                          |   Random Forest    |\n",
    "                          +--------------------+\n",
    "                                   |\n",
    "     +-----------------------------+-----------------------------+\n",
    "     |                             |                             |\n",
    "+------------+             +------------+               +------------+\n",
    "|  Árbol #1  |             |  Árbol #2  |       ...     | Árbol #100 | (n_estimators)\n",
    "+------------+             +------------+               +------------+\n",
    "     |                             |                             |\n",
    " Predicción y₁             Predicción y₂               Predicción y₁₀₀\n",
    "     \\\\                             |                             /\n",
    "      \\\\___________________________ | ___________________________/\n",
    "                                   ↓\n",
    "                      Promedio de todas las predicciones\n",
    "                                   ↓\n",
    "                     → Predicción final del modelo (ŷ)\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Diferencias entre Submuestreo Aleatorio y Bootstrap en Ensembles\n",
    "\n",
    "Al construir modelos de tipo ensemble, como los árboles de decisión múltiples, es importante distinguir entre dos estrategias comunes para generar conjuntos de entrenamiento: el submuestreo aleatorio sin reemplazo y el muestreo bootstrap (con reemplazo). Aunque ambos parten del mismo dataset original, sus objetivos y mecanismos son distintos.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Submuestreo Aleatorio (Repeated Subsampling / Repeated Subtraining)\n",
    "\n",
    "- Se generan múltiples subconjuntos del dataset **sin reemplazo**, es decir, cada observación aparece una sola vez por subconjunto.\n",
    "- Se utilizan diferentes particiones aleatorias para simular distintos escenarios de entrenamiento.\n",
    "- Su propósito principal es **evaluar la robustez del modelo**, no construir un ensemble final.\n",
    "- No produce un modelo único consolidado, sino una distribución de métricas a partir de múltiples entrenamientos independientes.\n",
    "- Es una técnica útil para **validación repetida**, pero no reduce el error del modelo base.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Bootstrap (usado en Bagging y Random Forest) \n",
    "\n",
    "- Se generan subconjuntos de entrenamiento **con reemplazo**: algunas observaciones pueden aparecer múltiples veces y otras no estar presentes.\n",
    "- Cada subconjunto cubre en promedio el 63.2% de los casos únicos del dataset original.\n",
    "- Cada modelo (por ejemplo, cada árbol en un Random Forest) es entrenado sobre una muestra distinta y potencialmente sesgada.\n",
    "- La agregación posterior (por mayoría o promedio) **reduce la varianza del modelo final**, mejorando su estabilidad y generalización.\n",
    "- Es la base de técnicas de ensamble como Bagging y Random Forest.\n",
    "\n",
    "---\n",
    "\n",
    "#### Comparación Sintética\n",
    "\n",
    "| Característica                     | Submuestreo (sin reemplazo)           | Bootstrap (con reemplazo)         |\n",
    "|------------------------------------|----------------------------------------|-----------------------------------|\n",
    "| Reemplazo                          | No                                     | Sí                                |\n",
    "| Objetivo principal                 | Evaluación de estabilidad              | Reducción de varianza             |\n",
    "| Construye ensemble final           | No                                     | Sí                                |\n",
    "| Diversidad entre modelos           | Limitada                               | Alta                              |\n",
    "| Tamaño de cada muestra             | < 100%, sin repetidos                  | ≈ 100%, con repetidos             |\n",
    "| Cobertura del dataset original     | Parcial                                | Total, pero heterogénea           |\n",
    "\n",
    "---\n",
    "\n",
    "El **submuestreo aleatorio** se utiliza para verificar si un modelo es sensible a pequeñas variaciones del conjunto de entrenamiento, mientras que el **bootstrap** es una estrategia explícita de mejora del modelo a través de agregación de múltiples predictores entrenados en datos modificados mediante muestreo con reemplazo.\n",
    "\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué hace un Random Forest?\n",
    "\n",
    "**Random Forest** es un algoritmo de aprendizaje supervisado que construye múltiples árboles de decisión para resolver problemas de clasificación o regresión. En lugar de apoyarse en un único árbol, crea un \"bosque\" de árboles que trabajan en conjunto para mejorar la precisión y la robustez del modelo.\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "1. **Bootstrap (muestreo aleatorio con reemplazo)**  \n",
    "   A partir del conjunto de entrenamiento original, se generan múltiples subconjuntos aleatorios —con reemplazo— del mismo tamaño. A esto se lo llama **bootstrap sampling**. Cada árbol del bosque se entrena con uno de estos subconjuntos distintos.\n",
    "\n",
    "2. **Entrenamiento de árboles independientes**  \n",
    "   Cada árbol se entrena de forma independiente, con su subconjunto bootstrap. Durante la construcción, en cada división interna del árbol, el algoritmo selecciona una muestra aleatoria de las variables disponibles (no todas), lo que introduce mayor diversidad estructural entre los árboles.\n",
    "\n",
    "3. **Agregación de resultados (votación)**  \n",
    "   Una vez entrenado el bosque, cada árbol emite una predicción. En clasificación, el resultado final del Random Forest se obtiene por **votación mayoritaria**: la clase que recibe más votos entre los árboles es la predicción final.\n",
    "\n",
    "#### ¿Por qué es eficaz?\n",
    "\n",
    "- **Reduce el sobreajuste**: la variabilidad introducida por el bootstrap y la selección aleatoria de variables impide que los árboles se adapten demasiado al ruido.\n",
    "- **Mejora la generalización**: al combinar muchos modelos débiles, se obtiene un modelo fuerte con menor varianza.\n",
    "- **Es robusto a datos ruidosos y desbalanceados**, aunque en estos casos puede requerir ajustes adicionales (como balanceo de clases o ajuste de pesos).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "El **rol central del Random Forest** no es necesariamente mejorar drásticamente la eficiencia predictiva frente al mejor árbol individual, sino **reducir el sobreajuste** y garantizar que los resultados sean **más estables y robustos** frente a nuevas muestras.\n",
    "\n",
    "Al trabajar con múltiples árboles entrenados sobre diferentes subconjuntos aleatorios (bootstrap) y seleccionando aleatoriamente las variables en cada división, el modelo reduce la dependencia de particularidades del conjunto de entrenamiento. Esto produce una **mejora en la generalización**, incluso si no incrementa notablemente la precisión o el recall en un caso puntual.\n",
    "\n",
    "En este sentido, la ganancia clave está en la **consistencia del modelo**, no tanto en una mejora automática y sustancial del rendimiento global. Esto es especialmente importante en contextos con ruido, alta dimensionalidad o cuando se requiere replicabilidad del desempeño en distintos cortes del mismo problema.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report\n",
    ")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_cat']\n",
    "\n",
    "# División fija\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "min_leaf = int(len(X_train) * 0.01)\n",
    "min_split = int(len(X_train) * 0.021)\n",
    "max_depth = 40\n",
    "seed = 42\n",
    "\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_leaf=min_leaf,\n",
    "    min_samples_split=min_split,\n",
    "    random_state=seed,\n",
    "    max_features=None\n",
    ")\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n=== RANDOM FOREST (max_features=None) ===\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"Precision (weighted): {prec_rf:.4f}\")\n",
    "print(f\"Recall (weighted): {rec_rf:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ¿Qué hace este Random Forest en particular?\n",
    "\n",
    "Este modelo se entrena para predecir una variable categórica con tres clases: `nada`, `una` y `mas_de_una`, que indican cuántas ventas genera un usuario. Utiliza 11 variables explicativas que reflejan el comportamiento de navegación, las promociones y las condiciones contextuales.\n",
    "\n",
    "#### Configuración utilizada\n",
    "- **100 árboles**\n",
    "- **Máxima profundidad: 40**\n",
    "- **Muestras mínimas por hoja y por división: 2% del conjunto de entrenamiento**\n",
    "- **División fija entrenamiento/testeo (70% / 30%)**\n",
    "- **Semilla aleatoria fija (reproducibilidad)**\n",
    "\n",
    "#### Resultado observado\n",
    "El modelo muestra un fuerte sesgo hacia la clase mayoritaria (`mas_de_una`), con alta capacidad de detección en esa clase pero bajo desempeño en las restantes (`una`, `nada`). Esto indica que, aunque el bosque es más robusto que un solo árbol, todavía sufre el impacto del desbalance de clases.\n",
    "\n",
    "Este comportamiento es típico cuando no se aplican técnicas de balanceo ni ponderación en el entrenamiento, y debe corregirse si se requiere una cobertura uniforme en todas las categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es Feature Bagging?\n",
    "\n",
    "**Feature bagging** es una técnica que consiste en seleccionar aleatoriamente un subconjunto de variables (features) en cada nodo de cada árbol dentro de un Random Forest. \n",
    "\n",
    "Entonces,  evaluar todas las variables disponibles para determinar el mejor punto de corte mediante la minimización de entropía, el modelo restringe la selección a un subconjunto aleatorio de ellas. Es decir, en cada nodo, el criterio de partición se aplica sobre un conjunto reducido de variables, no sobre el total: va a ser TOTAL - FEATURES EXTRAIDAS, que se definen aleatoriamente. \n",
    "\n",
    "Esto introduce diversidad adicional entre los árboles y reduce la correlación entre ellos, lo cual mejora la robustez del modelo y disminuye el riesgo de sobreajuste.\n",
    "\n",
    "### Uso de `max_features=\"sqrt\"`\n",
    "\n",
    "En problemas de clasificación, el valor por defecto `max_features=\"sqrt\"` indica que en cada nodo, el modelo seleccionará aleatoriamente una cantidad de variables igual a la raíz cuadrada del total de variables disponibles. Esto:\n",
    "- Favorece la diversidad entre árboles.\n",
    "- Introduce ruido controlado.\n",
    "- Puede degradar el rendimiento sobre clases minoritarias si estas dependen de variables no seleccionadas.\n",
    "\n",
    "Es una práctica común que mejora la generalización, especialmente en datasets grandes o con alta dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report\n",
    ")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "df['ventas_cat'] = pd.cut(df['ventas'], bins=[-1, 0, 1, df['ventas'].max()],\n",
    "                        labels=['nada', 'una', 'mas_de_una'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_cat']\n",
    "\n",
    "# División fija\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "min_leaf = int(len(X_train) * 0.02)\n",
    "min_split = int(len(X_train) * 0.02)\n",
    "max_depth = 40\n",
    "seed = 42\n",
    "\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_leaf=min_leaf,\n",
    "    min_samples_split=min_split,\n",
    "    random_state=seed,\n",
    "    max_features='sqrt' \n",
    ")\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n=== RANDOM FOREST con Feature Bagging ===\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"Precision (weighted): {prec_rf:.4f}\")\n",
    "print(f\"Recall (weighted): {rec_rf:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre Random Forest con y sin Feature Bagging\n",
    "\n",
    "A continuación se presenta una tabla con indicadores comparativos clave entre dos versiones del modelo Random Forest:\n",
    "\n",
    "| Métrica                | RF sin Feature Bagging | RF con Feature Bagging |\n",
    "|------------------------|------------------------|------------------------|\n",
    "| Accuracy               | 0.4177                 | 0.4267                 |\n",
    "| Precision (weighted)   | 0.3487                 | 0.5377                 |\n",
    "| Recall (weighted)      | 0.4177                 | 0.4267                 |\n",
    "| F1 Score (weighted)    | 0.3064                 | 0.2880                 |\n",
    "| F1 \"mas_de_una\"        | 0.58                   | 0.59                   |\n",
    "| F1 \"nada\"              | 0.02                   | 0.00                   |\n",
    "| F1 \"una\"               | 0.16                   | 0.10                   |\n",
    "| F1 Macro               | 0.25                   | 0.23                   |\n",
    "| F1 Weighted            | 0.31                   | 0.29                   |\n",
    "\n",
    "**Interpretación general:**\n",
    "\n",
    "\n",
    "- **Accuracy:** mejora levemente con feature bagging (0.4267 vs 0.4177), pero esta diferencia es marginal.\n",
    "- **Precision (weighted):** mejora notable con feature bagging (0.5377), indicando que, cuando predice una clase, lo hace con mayor acierto.\n",
    "- **Recall (weighted):** se mantiene prácticamente igual, sin mejoras significativas.\n",
    "- **F1 Score (weighted):** es **más bajo con feature bagging**, lo que sugiere que el modelo es menos equilibrado entre precision y recall en general.\n",
    "- **F1 Macro:** también **baja** con feature bagging. Esto significa que, en promedio, el desempeño por clase es peor, sobre todo en las minoritarias.\n",
    "- **Desempeño por clase:** el modelo con feature bagging se concentra más en la clase mayoritaria (\"mas_de_una\") y **abandona completamente la clase \"nada\"**, cuyo F1 cae a 0.00.\n",
    "\n",
    "\n",
    "> Feature bagging incrementa la precisión cuando el modelo acierta, pero **sacrifica la cobertura de clases minoritarias**, resultando en un modelo más sesgado hacia la clase mayoritaria. Aunque el `accuracy` mejora ligeramente, el balance general del modelo **empeora**, lo cual se refleja en los F1 promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aclaración sobre el desempeño CON Y SIN FEATURE BAGGING**\n",
    "\n",
    "Aunque en general el uso de *feature bagging* en Random Forest **mejora la robustez** y la capacidad de **generalización** del modelo, su efecto NO SIEMPRE implica una mejora en las métricas.\n",
    "\n",
    "En este caso, la activación de `max_features='sqrt'` mejora la `precision_weighted` y la `accuracy`, lo que sugiere UNA MEJOR DISCRIMINACIÓN sobre la clase MAYORITARIA. Sin embargo, el `F1 macro` y el `F1 weighted` empeoran, lo que INDICA UN MAYOR DESEQUILIBRIO en el rendimiento ENTRE clases.\n",
    "\n",
    "Esto se debe a que, al limitar las variables consideradas por nodo, **el modelo pierde acceso a variables claves para clasificar correctamente las clases minoritarias**, que ya estaban en desventaja por su bajo soporte (n de clase). Por tanto, aunque el modelo es más robusto en términos de agregación, su capacidad para cubrir bien todas las clases disminuye.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Interpretación del desempeño del modelo Random Forest\n",
    "\n",
    "**1. Precisión global (`accuracy`)**\n",
    "- El modelo acierta en el 42.67% de los casos, lo cual es apenas superior al azar si se considera el desbalance de clases.\n",
    "- Sin embargo, la `precision` ponderada es alta (0.5377) - cuando el modelo predice una clase, suele acertarla.\n",
    "\n",
    "**2. Desempeño por clase**\n",
    "- **Clase \"mas_de_una\"**: excelente `recall` (0.95), pero con `precision` moderada (0.43). El modelo predice esta clase con frecuencia y acierta la mayoría, aunque incluye varios falsos positivos.\n",
    "- **Clase \"nada\"**: `recall` de 0.00, lo que indica que el modelo prácticamente nunca la predice correctamente, a pesar de su `precision` artificialmente alta (1.00), producto de muy pocas o ninguna predicción efectiva.\n",
    "- **Clase \"una\"**: pobre desempeño general, con `recall` 0.06 y `f1` muy bajo (0.10), lo que refleja dificultad en distinguir esta clase de las otras.\n",
    "\n",
    "**3. Promedios**\n",
    "- `Macro avg` (0.23 en F1) expone un desequilibrio grave: el modelo se concentra en una sola clase.\n",
    "- `Weighted avg` (0.29 en F1) también es bajo, lo que evidencia que incluso ponderando por soporte, la calidad general es limitada.\n",
    "\n",
    "**4. Entonces**\n",
    "- El modelo Random Forest se especializa en predecir la clase **\"mas_de_una\"**, sacrificando completamente la capacidad de identificar correctamente las otras clases.\n",
    "- Este comportamiento sugiere **un problema serio de desbalance de clases no corregido**, lo cual limita la utilidad práctica del modelo si se requiere cobertura razonable en las clases \"una\" y \"nada\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# nota 1: depth en el forest\n",
    "\n",
    "En RandomForestClassifier, si no se especifica el parámetro max_depth, cada árbol crece hasta que todos los nodos son puros o contienen menos que min_samples_split observaciones. Es decir:\n",
    "\n",
    "- Por defecto, el depth de cada árbol en un random forest es ilimitado (max_depth=None).\n",
    "- Esto implica que cada árbol individual puede sobreajustar, pero el conjunto (promediado o por votación) no lo hace fácilmente gracias a:\n",
    "  - Bootstrapping (diferente subconjunto de datos por árbol)\n",
    "  - Submuestreo de variables (cada split evalúa sólo un subconjunto aleatorio de variables)\n",
    "\n",
    "\n",
    "### Nosotros ponemos depth 40 porque sabemos el optimal depth == 33\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nota 2: subsampling o forest?\n",
    "\n",
    "### Round 2: Diferencias entre Repeated Subsampling y Random Forest\n",
    "\n",
    "**1. Repeated Subsample**  \n",
    "Este método consiste en entrenar el mismo modelo base (por ejemplo, un árbol de decisión) sobre múltiples *subconjuntos aleatorios* del dataset original (sin reemplazo), evaluando luego sobre el conjunto completo. Es útil para estimar la **robustez y estabilidad del modelo** ante distintas particiones, pero **no cambia la estructura del modelo** ni su forma de predecir.\n",
    "\n",
    "- Su alta performance aquí refleja que **algunas particiones permiten encontrar árboles muy efectivos**, pero **no hay agregación de árboles**.\n",
    "- Puede sobreestimar el rendimiento si las particiones favorecen patrones particulares o repiten estructuras fáciles de ajustar.\n",
    "\n",
    "**2. Random Forest con Feature Bagging**  \n",
    "Random Forest es un modelo *ensamblado*, que entrena múltiples árboles sobre subconjuntos *con reemplazo* (bootstrap) **y además** selecciona aleatoriamente un subconjunto de variables por nodo (feature bagging). Las predicciones se agregan mediante votación (clasificación) o promedio (regresión).\n",
    "\n",
    "- Tiene más robustez general, pero **el feature bagging introduce ruido estructural** para evitar el sobreajuste.\n",
    "- Su objetivo es minimizar la varianza a costa de un posible aumento del sesgo.\n",
    "- Por esta razón, **la performance individual de cada árbol puede ser más baja**, pero el conjunto debería ser más confiable **en generalización**.\n",
    "\n",
    "\n",
    "### A cuál le creo?\n",
    "\n",
    "- **Repeated subsample** muestra qué tan bien puede funcionar un árbol en ciertos cortes de datos. No representa un modelo operativo, sino un diagnóstico.\n",
    "- **Random Forest** es un modelo real, diseñado para funcionar con datos nuevos y evitar sobreajuste. Su performance puede ser más modesta, pero es **más estable y confiable** frente a nuevas observaciones.\n",
    "\n",
    "**Entonces**: el rendimiento de repeated subsample no es comparable directamente con el de Random Forest. El primero es diagnóstico; el segundo, una solución robusta. En producción, **creerle al Random Forest**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Soluciones? \n",
    "\n",
    "### Estimemos el modelo con una clase dual en lugar de tres clases\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report\n",
    ")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "# Recodificación binaria de la variable objetivo\n",
    "df['ventas_bin'] = np.where(df['ventas'] == 0, 'sin_ventas', 'con_ventas')  # si ventas == 0 → \"sin_ventas\", si no → \"con_ventas\"\n",
    "# Alternativa usando pd.cut:\n",
    "# df['ventas_bin'] = pd.cut(df['ventas'], bins=[-1, 0, df['ventas'].max()], labels=['sin_ventas', 'con_ventas'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_bin']\n",
    "\n",
    "# División fija\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "# Random Forest con feature bagging\n",
    "min_leaf = int(len(X_train) * 0.02)\n",
    "min_split = int(len(X_train) * 0.02)\n",
    "max_depth = 40\n",
    "seed = 42\n",
    "\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_leaf=min_leaf,\n",
    "    min_samples_split=min_split,\n",
    "    random_state=seed,\n",
    "    max_features='sqrt'\n",
    ")\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n=== RANDOM FOREST BINARIO (nada vs algo) ===\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"Precision (weighted): {prec_rf:.4f}\")\n",
    "print(f\"Recall (weighted): {rec_rf:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de desempeño: Random Forest Multiclase vs Binario\n",
    "\n",
    "| Métrica                          | Fórmula y Explicación                    | RF Multiclase (3 clases) | RF Binario (sin_ventas vs con_ventas) |\n",
    "|----------------------------------|------------------------------------------|---------------------------|----------------------------------------|\n",
    "| **Accuracy**                     | $\\frac{TP + TN}{N}$     | 0.4267                    | 0.7530                                 |\n",
    "|                                  | Proporción de predicciones correctas     |                           |                                        |\n",
    "| **Precision (weighted)**         | $\\frac{TP}{TP + FP}$                     | 0.5377                    | 0.5670                                 |\n",
    "|                                  | Proporción de positivos correctos        |                           |                                        |\n",
    "| **Recall (weighted)**            | $\\frac{TP}{TP + FN}$                     | 0.4267                    | 0.7530                                 |\n",
    "|                                  | Proporción de casos positivos efectivos (cuántas veces acerté ventas) |                           |                                        |\n",
    "| **F1 Score (weighted)**          | $2 \\times \\frac{precision \\times recall}{precision + recall}$ | 0.2880                    | 0.6469                                 |\n",
    "|                                  | Media armónica entre precisión y recall  |                           |                                        |\n",
    "| **F1 Score (macro)**             | Promedio de F1 por clase                 | 0.2300                    | 0.4300                                 |\n",
    "|                                  | Equilibrio entre clases                  |                           |                                        |\n",
    "| **Soporte clase minoritaria**    | Número de casos en clase menos frecuente | 741                       | 741                                    |\n",
    "|                                  | Tamaño de la clase más pequeña           |                           |                                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Qué ganamos con el modelo binario?\n",
    "\n",
    "- El modelo binario mejora considerablemente la **capacidad predictiva general**, como se observa en las métricas de `accuracy`, `recall` y `f1-weighted`.\n",
    "- Al reducir el número de clases, **simplifica la tarea de clasificación** y permite enfocar la capacidad del modelo en distinguir casos de interés práctico (ventas vs no ventas).\n",
    "- Aporta una **mejor interpretación del fenómeno de conversión**, al distinguir simplemente entre clientes con y sin respuesta.\n",
    "\n",
    "\n",
    "- La categoría `\"con_ventas\"` captura exitosamente todos los casos positivos (`recall` cercano a 1), lo cual puede ser útil en tareas de priorización o segmentación comercial. Esto significa que el modelo tiene una alta sensibilidad para detectar usuarios que efectivamente realizaron al menos una compra, minimizando los falsos negativos (FN). En contextos comerciales, esta capacidad resulta valiosa porque permite identificar con gran confianza a los usuarios que respondieron a una campaña, interactuaron con éxito con una promoción o mostraron comportamiento de conversión.\n",
    "\n",
    "- Si bien el modelo aún falla en identificar correctamente los casos `\"sin_ventas\"` (precisión y recall de 0), su rendimiento sobre `\"con_ventas\"` revela una fuerte asimetría que puede aprovecharse operativamente. En particular, puede utilizarse como modelo de filtrado primario para identificar universos con alta probabilidad de conversión, sabiendo que el costo del error está mayormente concentrado en los usuarios no compradores, lo cual puede ser tolerable dependiendo del objetivo de negocio.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoque condicional sobre la categoría no explicada (sin ventas)\n",
    "\n",
    "- **Segmentación analítica focalizada**: al aislar únicamente los casos de `\"sin_ventas\"` y analizar sus características internas, se pueden identificar patrones estructurales que los diferencian del resto. Esto permite construir un modelo adaptado exclusivamente a explicar la no conversión.\n",
    "\n",
    "- **Problemas de desbalance corregidos ex post**: en el modelo original, `\"sin_ventas\"` es minoritaria y por tanto opacada en el proceso de aprendizaje. Al analizarla de forma independiente, se evita que el modelo la ignore.\n",
    "\n",
    "- **Modelos especializados por subgrupo**: esta estrategia permite diseñar árboles o ensambles que capturen relaciones sutiles que se pierden en el conjunto completo. Es útil especialmente si se sospecha que el comportamiento de no compra responde a mecanismos propios (barrera de acceso, segmentación por perfil, precios, etc.).\n",
    "\n",
    "- **Exploración de hipótesis diferenciadas**: sobre la población de `\"sin_ventas\"` puede testearse si existen razones estructurales o contextuales que expliquen la no conversión (por ejemplo, no logueados, navegación breve, falta de promociones visibles, etc.), algo que sería difícil de ver en un modelo general.\n",
    "\n",
    "- **Complemento explicativo, no sustituto**: el objetivo no es reemplazar el modelo original, sino complementarlo. Se trataría de una segunda capa analítica que profundiza en la parte mal explicada del conjunto completo.\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "Esto puede implementarse fácilmente construyendo un nuevo DataFrame `df_nada = df[df['ventas_bin'] == 'sin_ventas']` y redefiniendo los modelos sobre esa subpoblación. El análisis resultante puede arrojar pistas clave sobre cómo mejorar estrategias de retención, rediseñar la interfaz de navegación o repensar la asignación de promociones. Aquí habría que arrancar nuevamente desde las regresiones, árbol y luego forest. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de trabajo y variantes de Random Forest para reducir overfitting y aumentar generalización\n",
    "\n",
    "1. Bootstrapping (bagging de observaciones)\n",
    "\n",
    "2. Submuestreo de variables por nodo (feature bagging)\n",
    "\n",
    "3. Corte por profundidad (max_depth)\n",
    "\n",
    "4. Tamaño mínimo de nodos (min_samples_split)\n",
    "\n",
    "5. Número de árboles (n_estimators)\n",
    "\n",
    "6. Bagging con corte estructurado (blocked bagging / temporal bagging)\n",
    "\n",
    "7. Técnicas combinadas: Extremely Randomized Trees (ExtraTrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de trabajo y variantes de Random Forest para reducir overfitting y aumentar generalización\n",
    "\n",
    "El algoritmo de Random Forest combina múltiples árboles de decisión y les introduce **variación aleatoria** para generar diversidad entre ellos. Esa diversidad es clave para reducir el sobreajuste (*overfitting*). A continuación se listan y explican las principales técnicas utilizadas para \"generar ruido controlado\", romper correlaciones y mejorar el rendimiento del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. **Bootstrapping (bagging de observaciones)**  \n",
    "- Cada árbol se entrena con una muestra aleatoria del dataset **con reemplazo**.  \n",
    "- Algunos casos se repiten, otros no se usan (≈ 63% únicos).  \n",
    "- **Objetivo**: Introducir variabilidad en los datos de entrenamiento para cada árbol.  \n",
    "- Reduce la varianza del modelo final al promediar árboles distintos.  \n",
    "\n",
    "##### 2. **Submuestreo de variables por nodo (feature bagging)**  \n",
    "- Para cada *split*, se selecciona aleatoriamente un subconjunto de variables (no todas).  \n",
    "- Clasificación: por defecto usa `sqrt(n_features)` variables por *split*.  \n",
    "- Regresión: por defecto usa `n_features / 3`.  \n",
    "- Evita que siempre se elijan las variables más fuertes, forzando diversidad entre árboles.  \n",
    "\n",
    "##### 3. **Corte por profundidad (`max_depth`)**  \n",
    "- Limita la profundidad máxima de cada árbol.  \n",
    "- Árboles menos profundos → más sesgo pero menos overfitting.  \n",
    "- Útil cuando hay variables correlacionadas o desbalance de clases.  \n",
    "\n",
    "##### 4. **Tamaño mínimo de nodos (`min_samples_split`)**  \n",
    "- `min_samples_split`: número mínimo de muestras para permitir un *split*.  \n",
    "- Impide que el árbol aprenda reglas basadas en pocos casos (reduce ruido).  \n",
    "- Valores altos generan árboles más simples y generalizables.  \n",
    "\n",
    "##### 5. **Número de árboles (`n_estimators`)**  \n",
    "- Más árboles mejoran la estabilidad del promedio o votación.  \n",
    "- No causa overfitting, pero aumenta costo computacional.  \n",
    "- Típicamente se usan entre 100-500 árboles (depende del dataset).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report\n",
    ")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "\n",
    "# Recodificación binaria de la variable objetivo\n",
    "df['ventas_bin'] = np.where(df['ventas'] == 0, 'sin_ventas', 'con_ventas')  # si ventas == 0 → \"sin_ventas\", si no → \"con_ventas\"\n",
    "# Alternativa usando pd.cut:\n",
    "# df['ventas_bin'] = pd.cut(df['ventas'], bins=[-1, 0, df['ventas'].max()], labels=['sin_ventas', 'con_ventas'])\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_bin']\n",
    "\n",
    "# División fija\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "# --- Random Forest con variantes explicitas (puntos 1 a 5) ---\n",
    "min_leaf = int(len(X_train) * 0.02)     # Punto 4: Tamaño mínimo de nodo hoja\n",
    "min_split = int(len(X_train) * 0.02)    # Punto 4: Muestras mínimas para split\n",
    "max_depth = 40                          # Punto 3: Límite de profundidad del árbol\n",
    "seed = 42                               \n",
    "\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,                  # Punto 5: Número de árboles a considerar en el forest\n",
    "    max_depth=max_depth,              # Punto 3\n",
    "    min_samples_leaf=min_leaf,        # Punto 4\n",
    "    min_samples_split=min_split,      # Punto 4\n",
    "    random_state=seed,                \n",
    "    max_features='sqrt'               # Punto 2: Feature Bagging\n",
    ")                                      # Punto 1 (implícito): Bootstrapping por defecto, es lo que hace el random forest\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n=== RANDOM FOREST BINARIO (sin_ventas vs con_ventas) ===\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"Precision (weighted): {prec_rf:.4f}\")\n",
    "print(f\"Recall (weighted): {rec_rf:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap \n",
    "\n",
    "## ARBOL: Un tree predice una clase para cada OBSERVACIÓN recorriendo su estructura desde la raíz hasta una hoja\n",
    "\n",
    "Para cada observación individual (fila del dataset), cada árbol la clasifica por su cuenta, es decir:\n",
    "\t•\tLa observa,\n",
    "\t•\tla hace descender por sus splits,\n",
    "\t•\ty aterriza en una hoja.\n",
    "    •\tEsa hoja tiene una distribución de clases (por ejemplo: [A: 10, B: 5])\n",
    "    •\tel árbol elige como clase final la mayoritaria en esa hoja (en este caso A).\n",
    "\n",
    "\n",
    "## FOREST: \n",
    "- considerando N arboles\n",
    "\t•\tCada árbol predice una clase para cada observación.\n",
    "\t•\tSe hace una votación por mayoría entre los árboles → se asigna la clase con más votos.\n",
    "\t•\tEn probabilidades, se cuentan cuántos árboles votaron por cada clase y se divide por N.\n",
    "    - Entonces, la votación es por observación, no global, y depende de la clase mayoritaria en la hoja alcanzada por esa observación en cada árbol.\n",
    "\n",
    "## Entropía\n",
    "    - La impureza se usa durante el entrenamiento, no durante la predicción del árbol.\n",
    "\t•\tSirve para decidir los splits.\n",
    "\t•\tNo influye directamente en la votación final.\n",
    "\t•\tPero sí en qué tan puras serán las hojas (y por ende, qué tan confiables serán los votos que emiten).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Votación en un Random Forest\n",
    "\n",
    "La votación en un Random Forest se basa en el principio del *ensemble*, donde múltiples árboles de decisión (cada uno con sus errores y sesgos propios) se combinan para producir una predicción agregada más estable y precisa.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo se construye cada árbol?\n",
    "\n",
    "1. **Bootstraping**  \n",
    "   - Se toma una muestra aleatoria con reemplazo del dataset original (de igual tamaño).  \n",
    "   - Esto introduce variabilidad: cada árbol ve una combinación distinta de datos.\n",
    "\n",
    "2. **Selección aleatoria de variables (random feature selection)**  \n",
    "   - Para cada división (*split*) en cada árbol, se selecciona aleatoriamente un subconjunto de variables (por ejemplo, √n si n es el total de features).  \n",
    "   - Esto evita que todos los árboles elijan siempre la misma variable dominante.\n",
    "\n",
    "3. **Entrenamiento independiente**  \n",
    "   - Cada árbol se entrena completo, sin podas ni regularizaciones cruzadas.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo se hace la votación?\n",
    "\n",
    "### a. Clasificación (problema discreto)\n",
    "\n",
    "Cada árbol predice una clase. Luego:\n",
    "\n",
    "- Se cuentan cuántos árboles predijeron cada clase.\n",
    "- La clase con mayoría de votos gana (majority voting).\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Árbol 1 → clase A  \n",
    "Árbol 2 → clase B  \n",
    "Árbol 3 → clase A  \n",
    "Árbol 4 → clase A  \n",
    "Árbol 5 → clase B  \n",
    "Resultado → clase A (3 votos sobre 5)\n",
    "\n",
    "---\n",
    "\n",
    "### b. Regresión (problema continuo)\n",
    "\n",
    "Cada árbol predice un valor numérico. Luego:\n",
    "\n",
    "- Se calcula el promedio de todas las predicciones.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Árbol 1 → 34.2  \n",
    "Árbol 2 → 36.7  \n",
    "Árbol 3 → 35.0  \n",
    "Resultado → (34.2 + 36.7 + 35.0) / 3 = 35.3\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Qué se obtiene además de la predicción?\n",
    "\n",
    "- En clasificación también pueden obtenerse probabilidades.\n",
    "- Si 7 de 10 árboles votan por clase A, entonces:  \n",
    "  P(A) = 0.7  \n",
    "  P(B) = 0.3  \n",
    "- Esto permite ordenar, rankear o calibrar las predicciones, por ejemplo para curvas ROC o scores de riesgo.\n",
    "\n",
    "---\n",
    "\n",
    "## Beneficio final\n",
    "\n",
    "La combinación de:\n",
    "\n",
    "- árboles distintos (por el bootstrap),  \n",
    "- que exploran distintos espacios de variables (por el feature bagging),  \n",
    "- y votan de forma agregada,  \n",
    "\n",
    "conduce a un modelo con menor varianza, menor riesgo de sobreajuste y mayor capacidad de generalización, incluso si cada árbol individual es débil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salidas gráficas de un random forest. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report,\n",
    "    roc_curve, auc,\n",
    "    precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"dataset_suscripciones.csv\")\n",
    "df['ventas_bin'] = np.where(df['ventas'] == 0, 0, 1)\n",
    "\n",
    "X = df[['clicks', 'tiempo_browsing', 'paginas_visitadas', 'edad',\n",
    "        'logueado', 'codigo_promocional', 'es_feriado', 'es_domingo',\n",
    "        'precio', 'descuento_pct', 'rating_promedio']].copy()\n",
    "y = df['ventas_bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=40,\n",
    "    min_samples_leaf=int(len(X_train) * 0.02),\n",
    "    min_samples_split=int(len(X_train) * 0.02),\n",
    "    random_state=42,\n",
    "    max_features='sqrt'\n",
    ")\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "y_pred_rf = modelo_rf.predict(X_test)\n",
    "y_proba_rf = modelo_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 1. Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_rf)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC - Random Forest')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Curva Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_rf)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Curva Precisión-Recall')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precisión-Recall - Random Forest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión - Random Forest')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Curva de Aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    modelo_rf, X_train, y_train, cv=5, scoring='f1_weighted',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
    ")\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, train_scores_mean, label='F1 en entrenamiento')\n",
    "plt.plot(train_sizes, test_scores_mean, label='F1 en validación')\n",
    "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
    "plt.ylabel('F1 Score (ponderado)')\n",
    "plt.title('Curva de Aprendizaje - Random Forest')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta curva ROC indica que el modelo Random Forest tiene una capacidad muy limitada para discriminar entre clases. El área bajo la curva (AUC = 0.56) es apenas superior a 0.5, lo cual implica que el modelo está muy cerca del azar.\n",
    "\n",
    "Lectura rápida:\n",
    "\t•\tLínea diagonal gris: representa el rendimiento de un modelo completamente aleatorio (AUC = 0.5).\n",
    "\t•\tCurva azul del modelo: muy cercana a la diagonal → el modelo no logra separar bien los positivos de los negativos.\n",
    "\t•\tAUC = 0.56: marginalmente mejor que el azar. Técnicamente, el modelo tiene una probabilidad del 56% de rankear un positivo por encima de un negativo, lo cual es muy pobre.\n",
    "\n",
    "Implicancia:\n",
    "\t•\tAunque el modelo tenga accuracy razonable, la discriminación real entre clases está fallando.\n",
    "\t•\tLa distribución de probabilidades predichas probablemente no esté bien calibrada.\n",
    "\t•\tEn problemas desbalanceados, esta métrica refleja mejor el desempeño que accuracy, porque no se ve engañada por la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
